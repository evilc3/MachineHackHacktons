{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What This NoteBook Include  \n",
    "1. Post Processing \n",
    "2. Ensemble method using Ml Models\n",
    "3. Ensemble method using DL Models (got me at 18 place out of 59)\n",
    "\n",
    "## to see preprocessing part refer to Mutlicalss classification \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import gc\n",
    "import pickle  as pk\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modules for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Modules for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "# Tools for preprocessing input data\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "# Tools for creating ngrams and vectorizing input data\n",
    "# import gensim\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "\n",
    "\n",
    "# Tools for building a model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional,Flatten,GlobalMaxPooling1D,MaxPool1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Tools for assessing the quality of model prediction\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,log_loss,f1_score\n",
    "\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pk.load(open('processed_train_data','rb'))\n",
    "test_data = pk.load(open('processed_test_data','rb'))\n",
    "\n",
    "train_data = train_data.append(train_data[train_data['Labels'] == 18])\n",
    "train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     405\n",
       "19    261\n",
       "4     243\n",
       "0     203\n",
       "5     141\n",
       "15    134\n",
       "1     116\n",
       "16    109\n",
       "11    104\n",
       "8      79\n",
       "14     75\n",
       "7      27\n",
       "2      25\n",
       "20     18\n",
       "13     15\n",
       "21      9\n",
       "12      4\n",
       "9       3\n",
       "3       2\n",
       "17      2\n",
       "18      2\n",
       "10      2\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.Labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Unbalanced Data By Splitting classes w.r.t the size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clsses with 200+ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes with 200+ samples in datset Int64Index([6, 19, 4, 0], dtype='int64')\n",
      "These samples will be trained by one model\n"
     ]
    }
   ],
   "source": [
    "classes = train_data.Labels.value_counts().index\n",
    "\n",
    "print('classes with 200+ samples in datset {}'.format(classes[train_data.Labels.value_counts().values > 200]))\n",
    "\n",
    "print('These samples will be trained by one model')\n",
    "\n",
    "\n",
    "\n",
    "class_model_1 = classes[train_data.Labels.value_counts().values > 200]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes with 100 + samples < 200+ samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes with 100+ samples but < 200+ in datset Int64Index([5, 15, 1, 16, 11], dtype='int64')\n",
      "These samples will be trained by one model\n"
     ]
    }
   ],
   "source": [
    "classes = train_data.Labels.value_counts().index\n",
    "\n",
    "samples  = train_data.Labels.value_counts().values\n",
    "\n",
    "print('classes with 100+ samples but < 200+ in datset {}'.format( \n",
    "    classes[(samples> 100) &  (samples < 200)]))\n",
    "\n",
    "print('These samples will be trained by one model')\n",
    "\n",
    "\n",
    "class_model_2 = classes[(samples> 100) &  (samples < 200)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes with < 100+ samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes with 100+ samples but < 200+ in datset Int64Index([8, 14, 7, 2, 20, 13, 21, 12, 9, 3, 17, 18, 10], dtype='int64')\n",
      "These samples will be trained by one model\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "classes = train_data.Labels.value_counts().index\n",
    "\n",
    "samples  = train_data.Labels.value_counts().values\n",
    "\n",
    "print('classes with 100+ samples but < 200+ in datset {}'.format( \n",
    "    classes[(samples < 100)] ))\n",
    "\n",
    "print('These samples will be trained by one model')\n",
    "\n",
    "\n",
    "class_model_3 = classes[(samples <100)]\n",
    "\n",
    "print(len(class_model_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a simple pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. classes [ 1  4  6  8 15 16 19]\n",
      "[ 8  4  6  6 16 15 19 15  1  6]\n",
      "accuracy 1.0\n",
      "[[0.11635422 0.11722429 0.17682101 0.20792566 0.14649872 0.11825384\n",
      "  0.11692224]\n",
      " [0.11628772 0.2093109  0.17570306 0.1177257  0.14612592 0.11791386\n",
      "  0.11693283]\n",
      " [0.11463685 0.11542628 0.27910711 0.11574459 0.14301449 0.11673956\n",
      "  0.11533112]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "tf_idf = TfidfVectorizer()\n",
    "\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "\n",
    "demo_data  = train_data[0:10]\n",
    "\n",
    "x = demo_data['processed_script']\n",
    "y = demo_data['Labels']\n",
    "\n",
    "# print(x.shape,y.shape)\n",
    "\n",
    "\n",
    "# print('sample',x[0])\n",
    "\n",
    "\n",
    "params = [('tf_idf',tf_idf),('lr',clf)]\n",
    "\n",
    "model_0 = Pipeline(params)\n",
    "\n",
    "\n",
    "model_0.fit(x,y)\n",
    "\n",
    "#evaluating the model\n",
    "\n",
    "print('No. classes',np.unique(y))\n",
    "\n",
    "\n",
    "\n",
    "pred = model_0.predict(x)\n",
    "\n",
    "print(pred)\n",
    "\n",
    "print('accuracy',accuracy_score(y,pred))\n",
    "\n",
    "\n",
    "print(model_0.predict_proba(x)[0:3])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.12380272, 0.12655122, 0.20304908, 0.12820703, 0.16141277,\n",
       "        0.13091352, 0.12606367]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseenlabel = train_data[train_data['Labels'] == 0]['processed_script'].values[0]\n",
    "\n",
    "print(model_0.predict([unseenlabel]))\n",
    "\n",
    "model_0.predict_proba([unseenlabel])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class = 0 [('the', 56246), ('look', 22902), ('get', 20009), ('back', 18206), ('int', 17161), ('one', 15022), ('you', 13591), ('ext', 13143), ('like', 12249), ('day', 11710)]\n",
      "class = 1 [('the', 30033), ('look', 13099), ('get', 10251), ('back', 9655), ('int', 8122), ('one', 7750), ('ext', 7665), ('you', 7278), ('day', 7031), ('like', 6482)]\n",
      "class = 2 [('the', 4377), ('look', 2454), ('get', 2073), ('back', 1829), ('head', 1382), ('like', 1297), ('you', 1283), ('hiccup', 1256), ('one', 1238), ('come', 1177)]\n",
      "class = 3 [('jim', 955), ('franklin', 689), ('the', 435), ('get', 302), ('look', 243), ('come', 235), ('door', 231), ('you', 230), ('man', 227), ('eleanor', 213)]\n",
      "class = 4 [('the', 44092), ('get', 28304), ('look', 27248), ('you', 19355), ('back', 18053), ('int', 18028), ('know', 17363), ('dont', 16941), ('like', 16322), ('she', 15110)]\n",
      "class = 5 [('the', 29045), ('get', 18899), ('look', 17848), ('int', 13431), ('back', 12897), ('you', 12380), ('know', 11004), ('dont', 9921), ('she', 9598), ('day', 9521)]\n",
      "class = 6 [('the', 86144), ('look', 49674), ('get', 45054), ('int', 35279), ('you', 33389), ('back', 32613), ('she', 30679), ('day', 29987), ('know', 29487), ('dont', 27615)]\n",
      "class = 7 [('the', 4449), ('look', 2621), ('get', 2348), ('back', 1820), ('come', 1499), ('you', 1440), ('and', 1409), ('jack', 1373), ('like', 1342), ('george', 1311)]\n",
      "class = 8 [('the', 17027), ('look', 8557), ('get', 6380), ('back', 6064), ('int', 5432), ('you', 4939), ('one', 4846), ('like', 4463), ('she', 4239), ('come', 4181)]\n",
      "class = 9 [('guy', 798), ('neff', 749), ('the', 690), ('gillis', 602), ('bruno', 504), ('look', 442), ('get', 433), ('phyllis', 393), ('norma', 392), ('shot', 378)]\n",
      "class = 10 [('mary', 607), ('anne', 526), ('valentin', 389), ('henry', 331), ('tolstoy', 294), ('sofya', 288), ('the', 274), ('look', 245), ('she', 241), ('day', 234)]\n",
      "class = 11 [('the', 26008), ('look', 11761), ('she', 10365), ('back', 9341), ('get', 8952), ('int', 8644), ('door', 7468), ('one', 6270), ('you', 6257), ('come', 5954)]\n",
      "class = 12 [('jim', 955), ('rob', 894), ('the', 868), ('szpilman', 507), ('get', 494), ('look', 435), ('you', 410), ('door', 380), ('like', 373), ('steve', 371)]\n",
      "class = 13 [('the', 2719), ('look', 1558), ('get', 1445), ('and', 1315), ('jack', 1153), ('back', 1127), ('you', 1049), ('dorothy', 1018), ('she', 968), ('man', 953)]\n",
      "class = 14 [('the', 15940), ('look', 10784), ('get', 8149), ('she', 7155), ('back', 6900), ('int', 6771), ('know', 5525), ('you', 5368), ('door', 5136), ('one', 5124)]\n",
      "class = 15 [('the', 22449), ('look', 15726), ('get', 13485), ('she', 12411), ('int', 10954), ('you', 10869), ('know', 10040), ('back', 9682), ('dont', 9071), ('day', 8750)]\n",
      "class = 16 [('the', 29740), ('look', 12341), ('get', 9923), ('int', 9713), ('back', 8859), ('one', 7422), ('like', 7161), ('you', 6537), ('she', 6403), ('ext', 5828)]\n",
      "class = 17 [('marian', 223), ('the', 173), ('pentcho', 128), ('disciple', 96), ('paula', 79), ('int', 70), ('day', 68), ('mia', 68), ('look', 61), ('voice', 56)]\n",
      "class = 18 [('speed', 1142), ('the', 540), ('racer', 490), ('int', 430), ('pop', 416), ('car', 396), ('remmington', 372), ('sprittle', 286), ('contd', 284), ('like', 240)]\n",
      "class = 19 [('the', 62259), ('look', 31785), ('get', 28145), ('back', 23785), ('int', 22716), ('she', 19742), ('you', 19039), ('one', 17490), ('know', 16517), ('door', 15788)]\n",
      "class = 20 [('the', 5217), ('look', 2167), ('get', 2121), ('back', 1685), ('day', 1581), ('one', 1416), ('take', 1350), ('you', 1328), ('ext', 1319), ('know', 1194)]\n",
      "class = 21 [('the', 2612), ('look', 1431), ('get', 1123), ('back', 1017), ('come', 859), ('ext', 856), ('wyatt', 855), ('and', 823), ('you', 773), ('west', 772)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "for i in range(22):\n",
    "    vocab = Counter()\n",
    "    for script in train_data[train_data.Labels ==i].processed_script:\n",
    "\n",
    "\n",
    "\n",
    "            vocab.update( script.split())\n",
    "\n",
    "    print(f'class = {i} {vocab.most_common(10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # creating the voca file:\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def get_vocab(x):\n",
    "    vocab = Counter()\n",
    "\n",
    "\n",
    "    for script in x:\n",
    "        vocab.update( script.split())\n",
    "        \n",
    "    return vocab\n",
    "\n",
    "\n",
    "\n",
    "# vocab = get_vocab(train_data.processed_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'right', 'voice', 'phone', 'moment', 'say', 'around', 'tell', 'then', 'good', 'like', 'two', 'get', 'stop', 'little', 'toward', 'know', 'john', 'he', 'time', 'turn', 'look', 'behind', 'well', 'house', 'put', 'but', 'thats', 'man', 'call', 'cut', 'find', 'go', 'they', 'ext', 'head', 'work', 'car', 'hand', 'you', 'int', 'move', 'cant', 'side', 'make', 'street', 'it', 'another', 'open', 'leave', 'sit', 'walk', 'dont', 'day', 'stand', 'try', 'front', 'night', 'face', 'guy', 'take', 'run', 'door', 'beat', 'light', 'want', 'contd', 'still', 'one', 'she', 'let', 'shot', 'way', 'thing', 'eye', 'what', 'pull', 'the', 'hear', 'talk', 'smile', 'window', 'away', 'long', 'watch', 'think', 'old', 'room', 'youre', 'close', 'and', 'come', 'this', 'his', 'back', 'hold', 'there', 'give', 'something', 'continued', 'start'}\n"
     ]
    }
   ],
   "source": [
    "top_100_counts = vocab.most_common(100)\n",
    "\n",
    "\n",
    "top_100_wordlist = set([word for word,_ in top_100_counts])\n",
    "print(top_100_wordlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove top_100 words Method 1 (not using this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1979/1979 [00:24<00:00, 81.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# # remove words which are not in vocab file\n",
    "# train_docs = []\n",
    "# import tqdm \n",
    "# for script in  tqdm.tqdm(train_data['processed_script']):\n",
    "    \n",
    "#     new_script = []\n",
    "#     for words in script.split():\n",
    "        \n",
    "#         if words not in top_100_wordlist and len(words) > 3 and words not in custom_list:\n",
    "#             new_script.append(words)\n",
    "#     train_docs.append(list(set(new_script)))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_count = list(map(lambda x : len(x),train_docs))\n",
    "\n",
    "# sb.kdeplot(word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapper method 1  Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mapper(script):\n",
    "    \n",
    "    new_script = []\n",
    "    for words in script.split():\n",
    "        \n",
    "        if words not in top_100_wordlist and len(words) > 3:\n",
    "            \n",
    "           new_script.append(words)\n",
    "        \n",
    "        \n",
    "    return ' '.join(new_script)  \n",
    "\n",
    "\n",
    "train_data['post_processed_script'] = train_data['processed_script'].map(mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class = 0 [('fire', 5267), ('foot', 4802), ('across', 4406), ('wall', 4286), ('floor', 3990), ('star', 3913), ('step', 3900), ('suddenly', 3704), ('reach', 3655), ('jack', 3643)]\n",
      "class = 1 [('jack', 4014), ('star', 2842), ('wall', 2691), ('fire', 2646), ('ship', 2511), ('foot', 2380), ('fall', 2255), ('suddenly', 2189), ('begin', 2116), ('across', 2115)]\n",
      "class = 2 [('hiccup', 1256), ('shrek', 1067), ('jack', 805), ('coraline', 790), ('woody', 750), ('mater', 708), ('buzz', 601), ('dragon', 587), ('donkey', 570), ('suddenly', 565)]\n",
      "class = 3 [('franklin', 689), ('eleanor', 213), ('louis', 157), ('love', 104), ('girl', 95), ('song', 91), ('helena', 83), ('fuck', 83), ('robbie', 78), ('people', 76)]\n",
      "class = 4 [('yeah', 6490), ('really', 5619), ('okay', 5113), ('jack', 4845), ('would', 4481), ('mean', 4466), ('girl', 4447), ('woman', 4373), ('shes', 4337), ('could', 4327)]\n",
      "class = 5 [('fuck', 3527), ('yeah', 3449), ('table', 2732), ('nick', 2696), ('wait', 2621), ('could', 2577), ('step', 2558), ('floor', 2543), ('across', 2514), ('didnt', 2513)]\n",
      "class = 6 [('woman', 8098), ('people', 8057), ('would', 7971), ('wait', 7506), ('yeah', 7289), ('first', 7241), ('table', 7163), ('girl', 7155), ('never', 7142), ('could', 7059)]\n",
      "class = 7 [('jack', 1373), ('george', 1311), ('dorothy', 1019), ('wall', 840), ('coraline', 790), ('mary', 746), ('sarah', 705), ('carl', 669), ('master', 637), ('vada', 621)]\n",
      "class = 8 [('bruce', 1561), ('suddenly', 1527), ('star', 1447), ('jack', 1446), ('david', 1428), ('scott', 1403), ('wall', 1378), ('billy', 1350), ('foot', 1347), ('begin', 1333)]\n",
      "class = 9 [('neff', 749), ('gillis', 602), ('bruno', 504), ('phyllis', 393), ('norma', 392), ('keyes', 328), ('anne', 227), ('betty', 170), ('dietrichson', 163), ('screentalk', 148)]\n",
      "class = 10 [('mary', 607), ('anne', 526), ('valentin', 389), ('henry', 331), ('tolstoy', 294), ('sofya', 288), ('thomas', 187), ('chertkov', 170), ('sasha', 154), ('king', 143)]\n",
      "class = 11 [('floor', 2367), ('wall', 2251), ('peter', 2186), ('sound', 2169), ('shes', 2084), ('across', 2043), ('reach', 2023), ('body', 1971), ('step', 1935), ('camera', 1893)]\n",
      "class = 12 [('szpilman', 507), ('steve', 371), ('laura', 286), ('barry', 208), ('furtwangler', 185), ('david', 181), ('german', 171), ('people', 161), ('emmi', 156), ('fuck', 149)]\n",
      "class = 13 [('jack', 1153), ('dorothy', 1018), ('sarah', 707), ('guido', 630), ('bialystock', 553), ('scarecrow', 513), ('mulan', 465), ('camera', 430), ('aladdin', 406), ('lion', 396)]\n",
      "class = 14 [('woman', 1679), ('white', 1665), ('shes', 1591), ('step', 1551), ('floor', 1549), ('across', 1489), ('girl', 1483), ('martin', 1478), ('doesnt', 1439), ('sound', 1434)]\n",
      "class = 15 [('love', 3396), ('jack', 3239), ('woman', 3184), ('harry', 3174), ('would', 2817), ('girl', 2758), ('really', 2717), ('shes', 2707), ('yeah', 2630), ('never', 2597)]\n",
      "class = 16 [('wall', 3067), ('fire', 2353), ('across', 2331), ('star', 2317), ('foot', 2259), ('begin', 2204), ('ship', 2126), ('floor', 2074), ('inside', 2031), ('suddenly', 2009)]\n",
      "class = 17 [('marian', 223), ('pentcho', 128), ('disciple', 96), ('paula', 79), ('prospect', 37), ('alexander', 32), ('across', 31), ('pentchos', 30), ('mother', 28), ('mischa', 27)]\n",
      "class = 18 [('speed', 1142), ('racer', 490), ('remmington', 372), ('sprittle', 286), ('announcer', 200), ('race', 184), ('chim', 176), ('prix', 168), ('grand', 166), ('trixie', 166)]\n",
      "class = 19 [('floor', 5288), ('across', 4927), ('step', 4900), ('wall', 4826), ('foot', 4771), ('star', 4576), ('reach', 4551), ('fuck', 4495), ('sound', 4465), ('inside', 4461)]\n",
      "class = 20 [('paul', 1041), ('soldier', 973), ('epps', 800), ('german', 778), ('miller', 748), ('jaeger', 745), ('harry', 691), ('fire', 685), ('willard', 645), ('schindler', 620)]\n",
      "class = 21 [('wyatt', 855), ('west', 772), ('clay', 716), ('horse', 668), ('rocklin', 666), ('django', 646), ('with', 626), ('macreedy', 529), ('mary', 484), ('gordon', 482)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "for i in range(22):\n",
    "    vocab2 = Counter()\n",
    "    for script in train_data[train_data.Labels ==i].post_processed_script:\n",
    "\n",
    "\n",
    "\n",
    "            vocab2.update( script.split())\n",
    "\n",
    "    print(f'class = {i} {vocab2.most_common(10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # creating the voca file:\n",
    "from collections import Counter\n",
    "\n",
    "new_vocab = get_vocab(train_data.post_processed_script)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 34356),\n",
       " ('across', 33946),\n",
       " ('step', 33778),\n",
       " ('wall', 33724),\n",
       " ('star', 33648),\n",
       " ('would', 33408)]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab.most_common(100)[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapper Filter 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "custom_list = ['with','whats','shes','onto']\n",
    "\n",
    "def mapper(script):\n",
    "    \n",
    "    new_script = []\n",
    "    for words in script.split():\n",
    "        \n",
    "        if words not in top_100_wordlist and len(words) > 3 and words not in custom_list:\n",
    "            \n",
    "           new_script.append(words)\n",
    "        \n",
    "        \n",
    "    return ' '.join(list(set(new_script))) \n",
    "\n",
    "\n",
    "train_data['post_processed_script'] = train_data['processed_script'].map(mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19631f8ae48>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sb.kdeplot(train_data.post_processed_script.map(lambda x : len(x.split())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # creating the voca file:\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "test_vocab = get_vocab(test_data.processed_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90303\n",
      "[('the', 197472), ('look', 99936), ('get', 89179), ('int', 73297), ('back', 71944), ('you', 63482), ('she', 61799), ('one', 56659), ('know', 54992), ('day', 52635), ('like', 52576), ('dont', 50889), ('come', 50613), ('take', 48883), ('go', 47111), ('and', 46471), ('ext', 45895), ('door', 45609), ('night', 45006), ('hand', 44094), ('room', 40777), ('turn', 39664), ('man', 37724), ('what', 34902), ('they', 34368), ('it', 33731), ('think', 33377), ('head', 33188), ('open', 32989), ('say', 32841), ('around', 32408), ('make', 32338), ('right', 31726), ('face', 31428), ('want', 30688), ('well', 30503), ('move', 30272), ('youre', 30083), ('contd', 30027), ('two', 29823), ('car', 29766), ('time', 29740), ('cut', 28465), ('away', 28233), ('stand', 27080), ('he', 26880), ('walk', 26818), ('eye', 26500), ('pull', 25607), ('but', 25109), ('start', 24513), ('thats', 24439), ('close', 24283), ('good', 23437), ('stop', 23358), ('continued', 22997), ('tell', 22915), ('way', 22821), ('watch', 22711), ('try', 22471), ('hold', 22329), ('behind', 21813), ('sit', 21558), ('let', 21495), ('leave', 21207), ('house', 21136), ('run', 21032), ('give', 21024), ('still', 20866), ('something', 20822), ('there', 20735), ('little', 19560), ('cant', 19385), ('smile', 19318), ('light', 19269), ('thing', 18818), ('this', 18565), ('find', 18309), ('another', 18139), ('put', 17711), ('front', 17600), ('voice', 17316), ('hear', 17175), ('jack', 17027), ('old', 16758), ('beat', 16612), ('shot', 16585), ('street', 16377), ('side', 16364), ('call', 16356), ('guy', 16236), ('then', 16206), ('work', 16181), ('wall', 15892), ('toward', 15866), ('talk', 15793), ('star', 15726), ('window', 15696), ('long', 15659), ('phone', 15593)]\n"
     ]
    }
   ],
   "source": [
    "print(len(test_vocab))\n",
    "print(test_vocab.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "custom_list = ['with','whats','shes','onto']\n",
    "\n",
    "def mapper(script):\n",
    "    \n",
    "    new_script = []\n",
    "    for words in script.split():\n",
    "        \n",
    "        if words not in top_100_wordlist and len(words) > 3 and words not in custom_list:\n",
    "            \n",
    "           new_script.append(words)\n",
    "        \n",
    "        \n",
    "    return ' '.join(list(set(new_script))) \n",
    "\n",
    "\n",
    "test_data['post_processed_script'] = test_data['processed_script'].map(mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19628485400>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sb.kdeplot(test_data.post_processed_script.map(lambda x : len(x.split())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Test Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # creating the voca file:\n",
    "from collections import Counter\n",
    "\n",
    "new_test_vocab  = get_vocab(test_data.post_processed_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87360"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_test_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4635"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "final_test_words = set([word for word,counter in new_test_vocab.items() if counter >100])\n",
    "\n",
    "len(final_test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mapper(script):\n",
    "    \n",
    "    new_script = []\n",
    "    for words in script.split():\n",
    "        \n",
    "        if words  in final_test_words:\n",
    "            \n",
    "           new_script.append(words)\n",
    "        \n",
    "        \n",
    "    return ' '.join(list(set(new_script))) \n",
    "\n",
    "\n",
    "test_data['post_processed_script'] = test_data['post_processed_script'].map(mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19656db7978>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sb.kdeplot(test_data.post_processed_script.map(lambda x : len(x.split())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last Train Data Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28033"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # creating the voca file:\n",
    "from collections import Counter\n",
    "\n",
    "final_train = get_vocab(train_data.post_processed_script)\n",
    "len(final_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8245"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(final_train))\n",
    "\n",
    "final_word_list = set([word for word,counter in final_train.items() if counter >100])\n",
    "\n",
    "len(final_word_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mapper(script):\n",
    "    \n",
    "    new_script = []\n",
    "    for words in script.split():\n",
    "        \n",
    "        if words  in final_word_list:\n",
    "            \n",
    "           new_script.append(words)\n",
    "        \n",
    "        \n",
    "    return ' '.join(list(set(new_script))) \n",
    "\n",
    "\n",
    "train_data['post_processed_script'] = train_data['post_processed_script'].map(mapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19658719400>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "sb.kdeplot(train_data.post_processed_script.map(lambda x : len(x.split())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pk.dump(train_data,open('post_processed_train','wb'))\n",
    "# pk.dump(test_data,open('post_processed_test','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = pk.load(open('post_processed_train','rb'))\n",
    "test_data = pk.load(open('post_processed_test','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8245"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_vocab(train_data.post_processed_script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8629"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_vocab(test_data.post_processed_script))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log loss without using Local Tokenizers 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Global Tokeinzer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    norm='l2',\n",
    "    min_df=0,\n",
    "    smooth_idf=False,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8245"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_global = TfidfVectorizer(norm='l2',\n",
    "    min_df=0,\n",
    "    smooth_idf=False,sublinear_tf=True)\n",
    "\n",
    "global_vocab = tf_global.fit(list(train_data['post_processed_script']) + list(test_data.post_processed_script))\n",
    "\n",
    "# global_metrix = tf_global.fit(train_data['post_processed_script'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8837"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_vocab.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning entire data (all the classes on one classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8867674589658237\n",
      "2.091899482680295\n"
     ]
    }
   ],
   "source": [
    "x_0 = []\n",
    "y_0 = []\n",
    "for i in range(22):\n",
    "    \n",
    "    if i == 6:\n",
    "         x_0.extend(train_data[train_data.Labels == i]['post_processed_script'][0:203])\n",
    "         y_0.extend(train_data[train_data.Labels == i]['Labels'][0:203])\n",
    "    else:\n",
    "        x_0.extend(train_data[train_data.Labels == i]['post_processed_script'])\n",
    "        y_0.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "\n",
    "clf_007 =  OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "\n",
    "clf_001= SVC(C = 10,probability=True,random_state = 3,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lb_1 = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "tf_Mat = tf_global.transform(x_0)\n",
    "\n",
    "# dimensionlaity reduction\n",
    "t_svd_1 = TruncatedSVD(n_components=30,random_state = 3)\n",
    "\n",
    "t_svd_1.fit(tf_Mat)\n",
    "\n",
    "t_Mat = t_svd_1.transform(tf_Mat)\n",
    "\n",
    "\n",
    "\n",
    "#Encoding The output\n",
    "lb_1.fit(y_0)\n",
    "labels = lb_1.transform(y_0)    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    t_Mat,\n",
    "    labels,\n",
    "    stratify = labels,\n",
    "    test_size=0.3,\n",
    "    shuffle = True,\n",
    "    random_state=3)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "clf_001.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# print(accuracy_score(clf_001.predict(X_test),y_test))\n",
    "\n",
    "print(log_loss(y_train,clf_001.predict_proba(X_train)))\n",
    "print(log_loss(y_test,clf_001.predict_proba(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "1.8863111543643873\n",
      "1.8863111543643873\n",
      "oneVSRest LR\n",
      "1.7539533552194708\n",
      "1.7539533552194708\n",
      "VotingClassifier\n",
      "1.7873961529885347\n",
      "1.7873961529885347\n",
      "svm\n",
      "1.8937641867600712\n",
      "1.8937641867600712\n",
      "oneVSRest LR\n",
      "1.7612927171600183\n",
      "1.7612927171600183\n",
      "VotingClassifier\n",
      "1.7938782574820833\n",
      "1.7938782574820833\n",
      "svm\n",
      "1.8858035344522146\n",
      "1.8858035344522146\n",
      "oneVSRest LR\n",
      "1.7593475301362327\n",
      "1.7593475301362327\n",
      "VotingClassifier\n",
      "1.7908940137546678\n",
      "1.7908940137546678\n",
      "svm\n",
      "1.9032793304342703\n",
      "1.9032793304342703\n",
      "oneVSRest LR\n",
      "1.7796046215900703\n",
      "1.7796046215900703\n",
      "VotingClassifier\n",
      "1.8101356896717455\n",
      "1.8101356896717455\n",
      "svm\n",
      "1.8842799107919332\n",
      "1.8842799107919332\n",
      "oneVSRest LR\n",
      "1.7623251706748486\n",
      "1.7623251706748486\n",
      "VotingClassifier\n",
      "1.792449312611471\n",
      "1.792449312611471\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sk = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "clf_007 =  LogisticRegression(C = 100)\n",
    "\n",
    "\n",
    "\n",
    "vc = VotingClassifier([('SVC',clf_001),('Lr',clf_007)],voting = 'soft',weights = [0.4,0.6])\n",
    "\n",
    "\n",
    "for train_index,test_index in sk.split(t_Mat,labels):\n",
    "    \n",
    "    train_x,train_y = t_Mat[train_index],labels[train_index]\n",
    "    test_x,test_y = t_Mat[train_index],labels[train_index]\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "    print('svm')\n",
    "\n",
    "    clf_001.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "    # print(accuracy_score(clf_001.predict(X_test),y_test))\n",
    "\n",
    "    print(log_loss(train_y,clf_001.predict_proba(train_x)))\n",
    "    print(log_loss(test_y,clf_001.predict_proba(test_x)))\n",
    "\n",
    "   \n",
    "\n",
    "    print('oneVSRest LR')\n",
    "    \n",
    "    clf_007.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "    # print(accuracy_score(clf_001.predict(X_test),y_test))\n",
    "\n",
    "    print(log_loss(train_y,clf_007.predict_proba(train_x)))\n",
    "    print(log_loss(test_y,clf_007.predict_proba(test_x)))\n",
    "\n",
    "\n",
    "    \n",
    "    print('VotingClassifier')\n",
    "    \n",
    "    vc.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "    # print(accuracy_score(clf_001.predict(X_test),y_test))\n",
    "\n",
    "    print(log_loss(train_y,vc.predict_proba(train_x)))\n",
    "    print(log_loss(test_y,vc.predict_proba(test_x)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST (from Xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalid-mlogloss:2.84646\n",
      "Will train until valid-mlogloss hasn't improved in 30 rounds.\n",
      "[1]\tvalid-mlogloss:2.70833\n",
      "[2]\tvalid-mlogloss:2.61241\n",
      "[3]\tvalid-mlogloss:2.55732\n",
      "[4]\tvalid-mlogloss:2.54492\n",
      "[5]\tvalid-mlogloss:2.52556\n",
      "[6]\tvalid-mlogloss:2.51371\n",
      "[7]\tvalid-mlogloss:2.51152\n",
      "[8]\tvalid-mlogloss:2.51807\n",
      "[9]\tvalid-mlogloss:2.53166\n",
      "[10]\tvalid-mlogloss:2.55605\n",
      "[11]\tvalid-mlogloss:2.57626\n",
      "[12]\tvalid-mlogloss:2.60061\n",
      "[13]\tvalid-mlogloss:2.63082\n",
      "[14]\tvalid-mlogloss:2.65748\n",
      "[15]\tvalid-mlogloss:2.68880\n",
      "[16]\tvalid-mlogloss:2.71142\n",
      "[17]\tvalid-mlogloss:2.73971\n",
      "[18]\tvalid-mlogloss:2.77234\n",
      "[19]\tvalid-mlogloss:2.80082\n",
      "[20]\tvalid-mlogloss:2.83589\n",
      "[21]\tvalid-mlogloss:2.85892\n",
      "[22]\tvalid-mlogloss:2.88718\n",
      "[23]\tvalid-mlogloss:2.90847\n",
      "[24]\tvalid-mlogloss:2.94241\n",
      "[25]\tvalid-mlogloss:2.97089\n",
      "[26]\tvalid-mlogloss:2.99938\n",
      "[27]\tvalid-mlogloss:3.02964\n",
      "[28]\tvalid-mlogloss:3.05906\n",
      "[29]\tvalid-mlogloss:3.09202\n",
      "[30]\tvalid-mlogloss:3.12106\n",
      "[31]\tvalid-mlogloss:3.14936\n",
      "[32]\tvalid-mlogloss:3.17930\n",
      "[33]\tvalid-mlogloss:3.20265\n",
      "[34]\tvalid-mlogloss:3.23816\n",
      "[35]\tvalid-mlogloss:3.26141\n",
      "[36]\tvalid-mlogloss:3.28603\n",
      "[37]\tvalid-mlogloss:3.30867\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalid-mlogloss:2.51152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from xgboost.sklearn import XGBClassifier # <3\n",
    "\n",
    "\n",
    "# xgb_params = {'eta': 0.3, \n",
    "#               'max_depth': 5, \n",
    "#               'subsample': 0.8, \n",
    "#               'colsample_bytree': 0.8, \n",
    "#               'objective': 'multi:softmax',\n",
    "#                'num_class':22,\n",
    "#               'eval_metric': 'mlogloss', \n",
    "#               'seed': 23\n",
    "#              }\n",
    "\n",
    "    \n",
    "# X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "#         t_Mat, labels, test_size=0.25, stratify = labels,random_state=23)    \n",
    "    \n",
    "    \n",
    "# d_train = xgb.DMatrix(X_train, y_train)\n",
    "# d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "\n",
    "# watchlist = [(d_valid, 'valid')]\n",
    "# xgb_model = xgb.train(xgb_params, d_train, 2000, \n",
    "#                   watchlist, verbose_eval=True,\n",
    "#                   early_stopping_rounds=30)\n",
    "\n",
    "# # print(model.attributes()['best_score'])\n",
    "# # print(log_loss(y_train,vc.predict_proba(X_train)))\n",
    "# # print(log_loss(y_test,vc.predict_proba(X_test_)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12134831460674157"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(X_valid)\n",
    "\n",
    "accuracy_score(y_valid,xgb_model.predict(dtest))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 5000)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 0.5881104033970276\n",
      "0.6506698552368734\n",
      "0.6506698552368734\n",
      "acc 0.5812146892655368\n",
      "0.657921047212862\n",
      "0.657921047212862\n",
      "acc 0.5756509500351865\n",
      "0.6657339699363314\n",
      "0.6657339699363314\n",
      "acc 0.5729312762973352\n",
      "0.6734408421301517\n",
      "0.6734408421301517\n",
      "acc 0.5824022346368715\n",
      "0.6620734449354548\n",
      "0.6620734449354548\n"
     ]
    }
   ],
   "source": [
    "# clf_777 = XGBClassifier(**xgb_params,n_estimators = 1000)\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb_params = {'eta': 0.3, \n",
    "              'max_depth': 5, \n",
    "              'subsample': 0.8, \n",
    "              'colsample_bytree': 0.8, \n",
    "              'objective': 'multi:softmax',\n",
    "               'num_class':22,\n",
    "              'eval_metric': 'mlogloss', \n",
    "              'seed': 23\n",
    "             }\n",
    "clf_777 = XGBClassifier(n_estimators  = 300,**xgb_params)\n",
    "\n",
    "sk = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "t_svd_1 = TruncatedSVD(n_components=19,random_state = 17)\n",
    "\n",
    "t_svd_1.fit(tf_Mat)\n",
    "\n",
    "t_Mat = t_svd_1.transform(tf_Mat)\n",
    "\n",
    "\n",
    "\n",
    "for train_index,test_index in sk.split(t_Mat,labels):\n",
    "    \n",
    "    \n",
    "    train_x,train_y = t_Mat[train_index],labels[train_index]\n",
    "    test_x,test_y = t_Mat[train_index],labels[train_index]\n",
    "    \n",
    "    \n",
    "     \n",
    "    clf_777.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "    print('acc',accuracy_score(clf_777.predict(test_x),test_y))\n",
    "\n",
    "    print(log_loss(train_y,clf_777.predict_proba(train_x)))\n",
    "    print(log_loss(test_y,clf_777.predict_proba(test_x)))\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pk.dump(clf_777,open('xgboost_0.65','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier\n",
      "[22:16:03] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\learner.cc:328: \n",
      "Parameters: { importance_type, missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.7195138200832065\n",
      "0.7195138200832065\n",
      "VotingClassifier\n",
      "[22:16:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\learner.cc:328: \n",
      "Parameters: { importance_type, missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.726265911917592\n",
      "0.726265911917592\n",
      "VotingClassifier\n",
      "[22:16:25] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.0.0\\src\\learner.cc:328: \n",
      "Parameters: { importance_type, missing, n_estimators } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-232-a96257d22735>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'VotingClassifier'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mvc_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[0mtransformed_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mle_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\voting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     99\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, y,\n\u001b[0;32m    100\u001b[0m                                                  sample_weight=sample_weight)\n\u001b[1;32m--> 101\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclfs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'drop'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m             )\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\ensemble\\voting.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[1;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[0;32m    821\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"objective\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    207\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1247\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0;32m   1248\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m                                                     dtrain.handle))\n\u001b[0m\u001b[0;32m   1250\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "vc_final = VotingClassifier([('SVC',clf_001),('Lr',clf_007),('xgboost',clf_777)],voting = 'soft',weights = [0.05,0.05,0.9])\n",
    "\n",
    "\n",
    "for train_index,test_index in sk.split(t_Mat,labels):\n",
    "    \n",
    "    train_x,train_y = t_Mat[train_index],labels[train_index]\n",
    "    test_x,test_y = t_Mat[train_index],labels[train_index]\n",
    "    \n",
    "    print('VotingClassifier')\n",
    "    \n",
    "    vc_final.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "    # print(accuracy_score(clf_001.predict(X_test),y_test))\n",
    "\n",
    "    print(log_loss(train_y,vc_final.predict_proba(train_x)))\n",
    "    print(log_loss(test_y,vc_final.predict_proba(test_x)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# todo tomorow :\n",
    "## 1 Remove the words form test data which are not present in train and reduce the size\n",
    "## 2 Make 3 predictions 1 VoterClassider ,2 Xgboost (single) , 3 (with xgboost)\n",
    "\n",
    "\n",
    "## maybe try the ensembly approach with the xgboost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8837\n"
     ]
    }
   ],
   "source": [
    "to_keep_vocab = global_vocab.vocabulary_\n",
    "print(len(to_keep_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8629"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_vocab(test_data.post_processed_script))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(849, 8837)\n",
      "(849, 19)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "X_test = test_data.post_processed_script\n",
    "\n",
    "X_mat = global_vocab.transform(X_test)\n",
    "\n",
    "\n",
    "print(X_mat.shape)\n",
    "\n",
    "X_trunc_metrix = t_svd_1.transform(X_mat)\n",
    "\n",
    "print(X_trunc_metrix.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hope = clf_777.predict_proba(X_trunc_metrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 22)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hope.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_2300.txt</td>\n",
       "      <td>0.0203746</td>\n",
       "      <td>0.256807</td>\n",
       "      <td>0.00192161</td>\n",
       "      <td>0.00271132</td>\n",
       "      <td>0.0134854</td>\n",
       "      <td>0.00103042</td>\n",
       "      <td>0.00724338</td>\n",
       "      <td>0.00202243</td>\n",
       "      <td>0.00886163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00468113</td>\n",
       "      <td>0.0183494</td>\n",
       "      <td>0.0105041</td>\n",
       "      <td>0.274478</td>\n",
       "      <td>0.000894042</td>\n",
       "      <td>0.107195</td>\n",
       "      <td>0.000909632</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.160558</td>\n",
       "      <td>0.0141483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_809.txt</td>\n",
       "      <td>0.0265346</td>\n",
       "      <td>0.115094</td>\n",
       "      <td>0.00112803</td>\n",
       "      <td>0.00601444</td>\n",
       "      <td>0.0195629</td>\n",
       "      <td>0.000644091</td>\n",
       "      <td>0.0102281</td>\n",
       "      <td>0.00383926</td>\n",
       "      <td>0.0101895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000963731</td>\n",
       "      <td>0.00792053</td>\n",
       "      <td>0.0173301</td>\n",
       "      <td>0.526997</td>\n",
       "      <td>0.00164413</td>\n",
       "      <td>0.0231886</td>\n",
       "      <td>0.000470582</td>\n",
       "      <td>0.0404494</td>\n",
       "      <td>0.172802</td>\n",
       "      <td>0.00890454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_1383.txt</td>\n",
       "      <td>0.059028</td>\n",
       "      <td>0.0702869</td>\n",
       "      <td>0.00239485</td>\n",
       "      <td>0.00288999</td>\n",
       "      <td>0.168255</td>\n",
       "      <td>0.000793414</td>\n",
       "      <td>0.00361499</td>\n",
       "      <td>0.00186513</td>\n",
       "      <td>0.085961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00135496</td>\n",
       "      <td>0.0192882</td>\n",
       "      <td>0.00780037</td>\n",
       "      <td>0.0280926</td>\n",
       "      <td>0.00192657</td>\n",
       "      <td>0.132114</td>\n",
       "      <td>0.00111556</td>\n",
       "      <td>0.00325115</td>\n",
       "      <td>0.0322461</td>\n",
       "      <td>0.335363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_983.txt</td>\n",
       "      <td>0.0228592</td>\n",
       "      <td>0.259413</td>\n",
       "      <td>0.00163687</td>\n",
       "      <td>0.00572888</td>\n",
       "      <td>0.0155225</td>\n",
       "      <td>0.00543341</td>\n",
       "      <td>0.00557773</td>\n",
       "      <td>0.0044616</td>\n",
       "      <td>0.0211099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0387234</td>\n",
       "      <td>0.0247196</td>\n",
       "      <td>0.0125988</td>\n",
       "      <td>0.200335</td>\n",
       "      <td>0.00113335</td>\n",
       "      <td>0.154933</td>\n",
       "      <td>0.00106765</td>\n",
       "      <td>0.0883508</td>\n",
       "      <td>0.0833734</td>\n",
       "      <td>0.0147211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_1713.txt</td>\n",
       "      <td>0.0525641</td>\n",
       "      <td>0.0489496</td>\n",
       "      <td>0.00121302</td>\n",
       "      <td>0.0134173</td>\n",
       "      <td>0.200672</td>\n",
       "      <td>0.00125134</td>\n",
       "      <td>0.0221602</td>\n",
       "      <td>0.00326262</td>\n",
       "      <td>0.311965</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00223729</td>\n",
       "      <td>0.070502</td>\n",
       "      <td>0.00943287</td>\n",
       "      <td>0.0305178</td>\n",
       "      <td>0.00337222</td>\n",
       "      <td>0.0526848</td>\n",
       "      <td>0.00478729</td>\n",
       "      <td>0.0160717</td>\n",
       "      <td>0.012502</td>\n",
       "      <td>0.0443438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       File_Name          0          1           2           3          4  \\\n",
       "0  file_2300.txt  0.0203746   0.256807  0.00192161  0.00271132  0.0134854   \n",
       "1   file_809.txt  0.0265346   0.115094  0.00112803  0.00601444  0.0195629   \n",
       "2  file_1383.txt   0.059028  0.0702869  0.00239485  0.00288999   0.168255   \n",
       "3   file_983.txt  0.0228592   0.259413  0.00163687  0.00572888  0.0155225   \n",
       "4  file_1713.txt  0.0525641  0.0489496  0.00121302   0.0134173   0.200672   \n",
       "\n",
       "             5           6           7           8  ...           12  \\\n",
       "0   0.00103042  0.00724338  0.00202243  0.00886163  ...   0.00468113   \n",
       "1  0.000644091   0.0102281  0.00383926   0.0101895  ...  0.000963731   \n",
       "2  0.000793414  0.00361499  0.00186513    0.085961  ...   0.00135496   \n",
       "3   0.00543341  0.00557773   0.0044616   0.0211099  ...    0.0387234   \n",
       "4   0.00125134   0.0221602  0.00326262    0.311965  ...   0.00223729   \n",
       "\n",
       "           13          14         15           16         17           18  \\\n",
       "0   0.0183494   0.0105041   0.274478  0.000894042   0.107195  0.000909632   \n",
       "1  0.00792053   0.0173301   0.526997   0.00164413  0.0231886  0.000470582   \n",
       "2   0.0192882  0.00780037  0.0280926   0.00192657   0.132114   0.00111556   \n",
       "3   0.0247196   0.0125988   0.200335   0.00113335   0.154933   0.00106765   \n",
       "4    0.070502  0.00943287  0.0305178   0.00337222  0.0526848   0.00478729   \n",
       "\n",
       "           19         20          21  \n",
       "0    0.034422   0.160558   0.0141483  \n",
       "1   0.0404494   0.172802  0.00890454  \n",
       "2  0.00325115  0.0322461    0.335363  \n",
       "3   0.0883508  0.0833734   0.0147211  \n",
       "4   0.0160717   0.012502   0.0443438  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_preds = pd.DataFrame(columns = train_data.Labels.unique().tolist())\n",
    "test_set_preds.insert(0, 'File_Name', test_data.File_Name)\n",
    "test_set_preds.iloc[:,1:] = last_hope\n",
    "#Reorder the columns to match the Sample_submission_file\n",
    "test_set_preds = test_set_preds[['File_Name',0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
    "#Write your submissions to an excel file\n",
    "test_set_preds.to_excel('xgboost_0.67.xlsx', index=False)\n",
    "test_set_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03072764683426654, 0.3301728750926622, 0.003534215424455707,\n",
       "       0.009383974257669896, 0.030960649041224326, 0.004085185928148056,\n",
       "       0.013001092050785142, 0.004681667875966317, 0.038708245765577604,\n",
       "       0.009360098833853173, 0.00350888281929223, 0.05425227517822947,\n",
       "       0.0035468558312326637, 0.03290232221842, 0.014953211564776909,\n",
       "       0.1509801529656939, 0.0035394544662308634, 0.0936290808486004,\n",
       "       0.0059040051830063335, 0.05699680297839011, 0.07785796989177841,\n",
       "       0.027313334949739643], dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_preds.iloc[0].values[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting classes Int64Index([6, 19, 4, 0], dtype='int64')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5417721518987342"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('predicting classes {}'.format(class_model_1))\n",
    "\n",
    "x_1 = []\n",
    "y_1 = []\n",
    "for i in class_model_1:\n",
    "    \n",
    "    if i == 6:\n",
    "         x_1.extend(train_data[train_data.Labels == i]['post_processed_script'][0:203])\n",
    "         y_1.extend(train_data[train_data.Labels == i]['Labels'][0:203])\n",
    "    \n",
    "    x_1.extend(train_data[train_data.Labels == i]['post_processed_script'])\n",
    "    y_1.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "clf2_1 = SVC(C = 10,probability=True,random_state = 3,gamma = 0.1)\n",
    "\n",
    "\n",
    "\n",
    "# tf_idf_1  = TfidfVectorizer()\n",
    "t_svd_1 = TruncatedSVD(n_components=17)\n",
    "\n",
    "lb_1 = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "#Encoding Input\n",
    "# vocab = tf_idf_1.fit(x_1)\n",
    "tf_Mat = tf_global.transform(x_1)\n",
    "\n",
    "# dimensionlaity reduction\n",
    "\n",
    "t_Mat = t_svd_1.fit_transform(tf_Mat)\n",
    "\n",
    "#Encoding The output\n",
    "lb_1.fit(y_1)\n",
    "labels = lb_1.transform(y_1)    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    t_Mat,\n",
    "    labels,\n",
    "    test_size=0.3,\n",
    "    shuffle = True,\n",
    "    random_state=3)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "clf2_1.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "accuracy_score(clf2_1.predict(X_test),y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0018500212556198\n",
      "1.0172510057486666\n"
     ]
    }
   ],
   "source": [
    "print(log_loss(y_train,clf2_1.predict_proba(X_train)))\n",
    "print(log_loss(y_test,clf2_1.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  4,  6, 19])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting classes Int64Index([5, 15, 1, 16, 11], dtype='int64')\n",
      "0.6043956043956044\n",
      "1.009030644070039\n",
      "1.0260782339401135\n"
     ]
    }
   ],
   "source": [
    "print('predicting classes {}'.format(class_model_2))\n",
    "\n",
    "x_2 = []\n",
    "y_2 = []\n",
    "for i in class_model_2:\n",
    "    \n",
    "    x_2.extend(train_data[train_data.Labels == i]['post_processed_script'])\n",
    "    y_2.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "# clf_2 = XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "clf2_2 = SVC(C = 10,probability=True,random_state = 3)\n",
    "\n",
    "clf1  = LogisticRegression()\n",
    "\n",
    "\n",
    "# tf_idf_2  = TfidfVectorizer()\n",
    "t_svd_2 = TruncatedSVD(n_components=20,random_state=3)\n",
    "lb_2 = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "#Encoding Input\n",
    "# vocab_2  = tf_idf_2.fit(x_2)\n",
    "tf_Mat_2 = tf_global.transform(x_2)\n",
    "\n",
    "# dimensionlaity reduction\n",
    "\n",
    "t_Mat_2 = t_svd_2.fit_transform(tf_Mat_2)\n",
    "\n",
    "#Encoding The output\n",
    "lb_2.fit(y_2)\n",
    "labels_2 = lb_2.transform(y_2)    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    t_Mat_2,\n",
    "    labels_2,\n",
    "    test_size=0.3,\n",
    "    shuffle = True,\n",
    "    random_state=3)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "clf2_2.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print(accuracy_score(clf2_2.predict(X_test),y_test))\n",
    "\n",
    "\n",
    "print(log_loss(y_train,clf2_2.predict_proba(X_train)))\n",
    "print(log_loss(y_test,clf2_2.predict_proba(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  5, 11, 15, 16])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_2.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='binary:logistic', random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting classes Int64Index([8, 14, 7, 2, 20, 13, 21, 12, 9, 3, 17, 18, 10], dtype='int64') length of 13\n",
      "8     79\n",
      "14    75\n",
      "7     27\n",
      "2     25\n",
      "dtype: int64\n",
      "0.9593068711010392\n",
      "1.0135385822479928\n"
     ]
    }
   ],
   "source": [
    "print('predicting classes {} length of {}'.format(class_model_3,len(class_model_3)))\n",
    "class_model_tmp = [8, 14, 7, 2,]\n",
    "x_3 = []\n",
    "y_3 = []\n",
    "for i in class_model_tmp:\n",
    "    \n",
    "    x_3.extend(train_data[train_data.Labels == i]['post_processed_script'])\n",
    "    y_3.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "\n",
    "    \n",
    "print(pd.Series(y_3).value_counts())\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "# clf_3 = XGBClassifier(max_depth=1, n_estimators=300, learning_rate=0.1,subsample=0.8,gamma = 2)\n",
    "\n",
    "\n",
    "\n",
    "clf2_3 = SVC(C = 200,probability=True,random_state = 3,gamma = 0.01)\n",
    "\n",
    "clf1  = LogisticRegression()\n",
    "\n",
    "\n",
    "# tf_idf_3  = TfidfVectorizer()\n",
    "t_svd_3 = TruncatedSVD(n_components=20)\n",
    "lb_3 = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "#Encoding Input\n",
    "# vocab_3  = tf_idf_3.fit(x_3)\n",
    "tf_Mat_3 = tf_global.transform(x_3)\n",
    "\n",
    "# dimensionlaity reduction\n",
    "\n",
    "t_Mat_3 = t_svd_3.fit_transform(tf_Mat_3)\n",
    "\n",
    "#Encoding The output\n",
    "lb_3.fit(y_3)\n",
    "labels_3 = lb_3.transform(y_3)    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    t_Mat_3,\n",
    "    labels_3,\n",
    "    test_size=0.3,\n",
    "    stratify= labels_3,\n",
    "    shuffle = True,\n",
    "    random_state=3)    \n",
    "    \n",
    "    \n",
    "\n",
    "clf2_3.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "accuracy_score(clf2_3.predict(X_test),y_test)\n",
    "\n",
    "print(log_loss(y_train,clf2_3.predict_proba(X_train)))\n",
    "print(log_loss(y_test,clf2_3.predict_proba(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting classes Int64Index([8, 14, 7, 2, 20, 13, 21, 12, 9, 3, 17, 18, 10], dtype='int64') length of 13\n",
      "20    18\n",
      "13    15\n",
      "21     9\n",
      "12     4\n",
      "9      3\n",
      "18     2\n",
      "17     2\n",
      "10     2\n",
      "3      2\n",
      "dtype: int64\n",
      "1.4301146368429867\n"
     ]
    }
   ],
   "source": [
    "print('predicting classes {} length of {}'.format(class_model_3,len(class_model_3)))\n",
    "class_model_tmp = [20, 13, 21, 12, 9, 3, 17, 18, 10]\n",
    "x_4 = []\n",
    "y_4 = []\n",
    "for i in class_model_tmp:\n",
    "    \n",
    "    x_4.extend(train_data[train_data.Labels == i]['post_processed_script'])\n",
    "    y_4.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "\n",
    "    \n",
    "print(pd.Series(y_4).value_counts())\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "# clf_3 = XGBClassifier(max_depth=1, n_estimators=300, learning_rate=0.1,subsample=0.8,gamma = 2)\n",
    "\n",
    "\n",
    "\n",
    "clf2_4 = SVC(C = 200,probability=True,random_state = 3,gamma = 0.01)\n",
    "\n",
    "clf1  = LogisticRegression()\n",
    "\n",
    "\n",
    "# tf_idf_3  = TfidfVectorizer()\n",
    "t_svd_4 = TruncatedSVD(n_components=20)\n",
    "lb_4 = LabelEncoder()\n",
    "\n",
    "\n",
    "\n",
    "#Encoding Input\n",
    "# vocab_3  = tf_idf_3.fit(x_3)\n",
    "tf_Mat_4 = tf_global.transform(x_4)\n",
    "\n",
    "# dimensionlaity reduction\n",
    "\n",
    "t_Mat_4 = t_svd_4.fit_transform(tf_Mat_4)\n",
    "\n",
    "#Encoding The output\n",
    "lb_4.fit(y_4)\n",
    "labels_4 = lb_4.transform(y_4)    \n",
    "    \n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     t_Mat_4,\n",
    "#     labels_4,\n",
    "#     test_size=0.2,\n",
    "#     stratify= labels_4,\n",
    "#     shuffle = True,\n",
    "#     random_state=3)    \n",
    "    \n",
    "    \n",
    "\n",
    "clf2_4.fit(t_Mat_4,labels_4)\n",
    "\n",
    "\n",
    "# accuracy_score(clf2_4.predict(X_test),y_test)\n",
    "\n",
    "print(log_loss(labels_4,clf2_4.predict_proba(X_train)))\n",
    "# print(log_loss(y_test,clf2_4.predict_proba(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  7,  8, 14])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb_3.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3843333333333332"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1.17 + 1.268 + 1.715 )/ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1979, 4)\n",
      "(1979, 4)\n",
      "[ 0  4  6 19]\n",
      "[ 1  5 11 15 16]\n",
      "[ 2  7  8 14]\n",
      "[ 3  9 10 12 13 17 18 20 21]\n",
      "(array([0], dtype=int64),) 0 0 [[0.17691243 0.11616426 0.54430632 0.16261698]\n",
      " [0.02303156 0.25972237 0.58029827 0.1369478 ]\n",
      " [0.10904387 0.00722144 0.44334848 0.44038621]\n",
      " ...\n",
      " [0.03589067 0.1333495  0.65322386 0.17753596]\n",
      " [0.24085114 0.08174546 0.30462671 0.37277669]\n",
      " [0.31919757 0.16741356 0.22560061 0.28778825]]\n",
      "(array([1], dtype=int64),) 4 0 [[0.17691243 0.11616426 0.54430632 0.16261698]\n",
      " [0.02303156 0.25972237 0.58029827 0.1369478 ]\n",
      " [0.10904387 0.00722144 0.44334848 0.44038621]\n",
      " ...\n",
      " [0.03589067 0.1333495  0.65322386 0.17753596]\n",
      " [0.24085114 0.08174546 0.30462671 0.37277669]\n",
      " [0.31919757 0.16741356 0.22560061 0.28778825]]\n",
      "(array([2], dtype=int64),) 6 0 [[0.17691243 0.11616426 0.54430632 0.16261698]\n",
      " [0.02303156 0.25972237 0.58029827 0.1369478 ]\n",
      " [0.10904387 0.00722144 0.44334848 0.44038621]\n",
      " ...\n",
      " [0.03589067 0.1333495  0.65322386 0.17753596]\n",
      " [0.24085114 0.08174546 0.30462671 0.37277669]\n",
      " [0.31919757 0.16741356 0.22560061 0.28778825]]\n",
      "(array([3], dtype=int64),) 19 0 [[0.17691243 0.11616426 0.54430632 0.16261698]\n",
      " [0.02303156 0.25972237 0.58029827 0.1369478 ]\n",
      " [0.10904387 0.00722144 0.44334848 0.44038621]\n",
      " ...\n",
      " [0.03589067 0.1333495  0.65322386 0.17753596]\n",
      " [0.24085114 0.08174546 0.30462671 0.37277669]\n",
      " [0.31919757 0.16741356 0.22560061 0.28778825]]\n",
      "(array([0], dtype=int64),) 1 0 [[0.46037446 0.06277508 0.09605505 0.25360824 0.12718717]\n",
      " [0.02887136 0.35626341 0.07257129 0.47688662 0.06540733]\n",
      " [0.12496618 0.13794775 0.40713055 0.03034136 0.29961416]\n",
      " ...\n",
      " [0.0628511  0.21146053 0.28774565 0.33159513 0.10634759]\n",
      " [0.14370183 0.05816505 0.47218081 0.02703431 0.29891801]\n",
      " [0.28953073 0.16331716 0.15294063 0.12807647 0.266135  ]]\n",
      "(array([1], dtype=int64),) 5 0 [[0.46037446 0.06277508 0.09605505 0.25360824 0.12718717]\n",
      " [0.02887136 0.35626341 0.07257129 0.47688662 0.06540733]\n",
      " [0.12496618 0.13794775 0.40713055 0.03034136 0.29961416]\n",
      " ...\n",
      " [0.0628511  0.21146053 0.28774565 0.33159513 0.10634759]\n",
      " [0.14370183 0.05816505 0.47218081 0.02703431 0.29891801]\n",
      " [0.28953073 0.16331716 0.15294063 0.12807647 0.266135  ]]\n",
      "(array([2], dtype=int64),) 11 0 [[0.46037446 0.06277508 0.09605505 0.25360824 0.12718717]\n",
      " [0.02887136 0.35626341 0.07257129 0.47688662 0.06540733]\n",
      " [0.12496618 0.13794775 0.40713055 0.03034136 0.29961416]\n",
      " ...\n",
      " [0.0628511  0.21146053 0.28774565 0.33159513 0.10634759]\n",
      " [0.14370183 0.05816505 0.47218081 0.02703431 0.29891801]\n",
      " [0.28953073 0.16331716 0.15294063 0.12807647 0.266135  ]]\n",
      "(array([3], dtype=int64),) 15 0 [[0.46037446 0.06277508 0.09605505 0.25360824 0.12718717]\n",
      " [0.02887136 0.35626341 0.07257129 0.47688662 0.06540733]\n",
      " [0.12496618 0.13794775 0.40713055 0.03034136 0.29961416]\n",
      " ...\n",
      " [0.0628511  0.21146053 0.28774565 0.33159513 0.10634759]\n",
      " [0.14370183 0.05816505 0.47218081 0.02703431 0.29891801]\n",
      " [0.28953073 0.16331716 0.15294063 0.12807647 0.266135  ]]\n",
      "(array([4], dtype=int64),) 16 0 [[0.46037446 0.06277508 0.09605505 0.25360824 0.12718717]\n",
      " [0.02887136 0.35626341 0.07257129 0.47688662 0.06540733]\n",
      " [0.12496618 0.13794775 0.40713055 0.03034136 0.29961416]\n",
      " ...\n",
      " [0.0628511  0.21146053 0.28774565 0.33159513 0.10634759]\n",
      " [0.14370183 0.05816505 0.47218081 0.02703431 0.29891801]\n",
      " [0.28953073 0.16331716 0.15294063 0.12807647 0.266135  ]]\n",
      "(array([0], dtype=int64),) 2 0 [[0.18082767 0.17947928 0.56882437 0.07086868]\n",
      " [0.063111   0.072576   0.25379504 0.61051796]\n",
      " [0.07705566 0.07016871 0.38012079 0.47265485]\n",
      " ...\n",
      " [0.10676084 0.13639802 0.37592602 0.38091512]\n",
      " [0.13585905 0.14477526 0.49826889 0.2210968 ]\n",
      " [0.16931933 0.19275151 0.51371057 0.12421859]]\n",
      "(array([1], dtype=int64),) 7 0 [[0.18082767 0.17947928 0.56882437 0.07086868]\n",
      " [0.063111   0.072576   0.25379504 0.61051796]\n",
      " [0.07705566 0.07016871 0.38012079 0.47265485]\n",
      " ...\n",
      " [0.10676084 0.13639802 0.37592602 0.38091512]\n",
      " [0.13585905 0.14477526 0.49826889 0.2210968 ]\n",
      " [0.16931933 0.19275151 0.51371057 0.12421859]]\n",
      "(array([2], dtype=int64),) 8 0 [[0.18082767 0.17947928 0.56882437 0.07086868]\n",
      " [0.063111   0.072576   0.25379504 0.61051796]\n",
      " [0.07705566 0.07016871 0.38012079 0.47265485]\n",
      " ...\n",
      " [0.10676084 0.13639802 0.37592602 0.38091512]\n",
      " [0.13585905 0.14477526 0.49826889 0.2210968 ]\n",
      " [0.16931933 0.19275151 0.51371057 0.12421859]]\n",
      "(array([3], dtype=int64),) 14 0 [[0.18082767 0.17947928 0.56882437 0.07086868]\n",
      " [0.063111   0.072576   0.25379504 0.61051796]\n",
      " [0.07705566 0.07016871 0.38012079 0.47265485]\n",
      " ...\n",
      " [0.10676084 0.13639802 0.37592602 0.38091512]\n",
      " [0.13585905 0.14477526 0.49826889 0.2210968 ]\n",
      " [0.16931933 0.19275151 0.51371057 0.12421859]]\n",
      "(array([0], dtype=int64),) 3 0 [[0.14486167 0.16150969 0.47801729 0.21561135]\n",
      " [0.17432358 0.18370196 0.51425049 0.12772397]\n",
      " [0.14441169 0.15201596 0.49639329 0.20717906]\n",
      " ...\n",
      " [0.16702983 0.1774128  0.50693259 0.14862478]\n",
      " [0.14579557 0.15273386 0.49264571 0.20882486]\n",
      " [0.13933544 0.127024   0.7083405  0.02530006]]\n",
      "(array([1], dtype=int64),) 9 0 [[0.14486167 0.16150969 0.47801729 0.21561135]\n",
      " [0.17432358 0.18370196 0.51425049 0.12772397]\n",
      " [0.14441169 0.15201596 0.49639329 0.20717906]\n",
      " ...\n",
      " [0.16702983 0.1774128  0.50693259 0.14862478]\n",
      " [0.14579557 0.15273386 0.49264571 0.20882486]\n",
      " [0.13933544 0.127024   0.7083405  0.02530006]]\n",
      "(array([2], dtype=int64),) 10 0 [[0.14486167 0.16150969 0.47801729 0.21561135]\n",
      " [0.17432358 0.18370196 0.51425049 0.12772397]\n",
      " [0.14441169 0.15201596 0.49639329 0.20717906]\n",
      " ...\n",
      " [0.16702983 0.1774128  0.50693259 0.14862478]\n",
      " [0.14579557 0.15273386 0.49264571 0.20882486]\n",
      " [0.13933544 0.127024   0.7083405  0.02530006]]\n",
      "(array([3], dtype=int64),) 12 0 [[0.14486167 0.16150969 0.47801729 0.21561135]\n",
      " [0.17432358 0.18370196 0.51425049 0.12772397]\n",
      " [0.14441169 0.15201596 0.49639329 0.20717906]\n",
      " ...\n",
      " [0.16702983 0.1774128  0.50693259 0.14862478]\n",
      " [0.14579557 0.15273386 0.49264571 0.20882486]\n",
      " [0.13933544 0.127024   0.7083405  0.02530006]]\n",
      "(array([4], dtype=int64),) 13 0 [[0.14486167 0.16150969 0.47801729 0.21561135]\n",
      " [0.17432358 0.18370196 0.51425049 0.12772397]\n",
      " [0.14441169 0.15201596 0.49639329 0.20717906]\n",
      " ...\n",
      " [0.16702983 0.1774128  0.50693259 0.14862478]\n",
      " [0.14579557 0.15273386 0.49264571 0.20882486]\n",
      " [0.13933544 0.127024   0.7083405  0.02530006]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-245-595dddc1b025>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_list\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpred_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mfinal_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "\n",
    "X = train_data['post_processed_script']\n",
    "Y = train_data['Labels']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction(svd,model,data_x,data_y):\n",
    "    \n",
    "    mat_x = tf_global.transform(data_x)\n",
    "    mat_x_svd = svd.transform(mat_x)\n",
    "    return model.predict_proba(mat_x_svd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(\"model 1\")\n",
    "# # for model 1 \n",
    "# pred1 = get_prediction(t_svd_1,clf2_1,X,Y)\n",
    "\n",
    "# print(\"model 2\")\n",
    "# #for model 2 \n",
    "# pred2 = get_prediction(t_svd_2,clf2_2,X,Y)\n",
    "\n",
    "# print(\"model 3\")\n",
    "# #for model 3 \n",
    "# pred3 = get_prediction(t_svd_3,clf2_3,X,Y)\n",
    "\n",
    "# print(\"model 4\")\n",
    "# #for model 4\n",
    "# pred4 = get_prediction(t_svd_4,clf2_4,X,Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(pred3.shape)\n",
    "print(pred4.shape)\n",
    "\n",
    "\n",
    "\n",
    "#label index order for model 1 \n",
    "index_model_1 = lb_1.classes_\n",
    "index_model_2 = lb_2.classes_\n",
    "index_model_3 = lb_3.classes_\n",
    "index_model_4 = lb_4.classes_\n",
    "\n",
    "\n",
    "print(index_model_1)\n",
    "print(index_model_2)\n",
    "print(index_model_3)\n",
    "print(index_model_4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "size = X.shape[0]\n",
    "\n",
    "final_pred = np.zeros((size,22),dtype = 'float32')\n",
    "\n",
    "\n",
    "for row in range(size):\n",
    "    \n",
    "    for index_list,pred_list in zip([index_model_1,index_model_2,index_model_3,index_model_4],\\\n",
    "                                    [pred1,pred2,pred3,pred4]):\n",
    "\n",
    "        for i in range(22):\n",
    "\n",
    "            if i in index_list:\n",
    "\n",
    "                index = np.where(index_list == i)\n",
    "                print(index,i,row,pred_list)\n",
    "                final_pred[row][i] = pred_list[row][index[0][0]]\n",
    "\n",
    "\n",
    "log_loss(train_data['Labels'].values,final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4  6 19]\n",
      "[ 1  5 11 15 16]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = test_data['post_processed_script']\n",
    "# Y = train_data['Labels']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_prediction(svd,model,data_x,data_y):\n",
    "    \n",
    "    mat_x = tf_global.transform(data_x)\n",
    "#     mat_x_svd = svd.transform(mat_x)\n",
    "    return model.predict_proba(mat_x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# for model 1 \n",
    "pred1 = get_prediction(t_svd_1,clf2_1,X,Y)\n",
    "\n",
    "#for model 2 \n",
    "pred2 = get_prediction(t_svd_2,clf2_2,X,Y)\n",
    "\n",
    "#for model 3 \n",
    "pred3 = get_prediction(t_svd_3,clf2_3,X,Y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#label index order for model 1 \n",
    "index_model_1 = lb_1.classes_\n",
    "index_model_2 = lb_2.classes_\n",
    "index_model_3 = lb_3.classes_\n",
    "\n",
    "print(index_model_1)\n",
    "print(index_model_2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "size = X.shape[0]\n",
    "\n",
    "final_pred = np.zeros((size,22),dtype = 'float32')\n",
    "\n",
    "\n",
    "for row in range(size):\n",
    "    \n",
    "    for index_list,pred_list in zip([index_model_1,index_model_2,index_model_3],[pred1,pred2,pred3]):\n",
    "\n",
    "        for i in range(22):\n",
    "\n",
    "            if i in index_list:\n",
    "\n",
    "                index = np.where(index_list == i)\n",
    "\n",
    "                final_pred[row][i] = pred_list[row][index[0][0]]\n",
    "\n",
    "\n",
    "# log_loss(train_data['Labels'].values,final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 22)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_2300.txt</td>\n",
       "      <td>0.0590446</td>\n",
       "      <td>0.110904</td>\n",
       "      <td>0.123339</td>\n",
       "      <td>0.00779356</td>\n",
       "      <td>0.269485</td>\n",
       "      <td>0.190301</td>\n",
       "      <td>0.408658</td>\n",
       "      <td>0.0905355</td>\n",
       "      <td>0.266962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0278881</td>\n",
       "      <td>0.0536573</td>\n",
       "      <td>0.318561</td>\n",
       "      <td>0.293053</td>\n",
       "      <td>0.163751</td>\n",
       "      <td>0.00729391</td>\n",
       "      <td>0.00786818</td>\n",
       "      <td>0.262812</td>\n",
       "      <td>0.0469967</td>\n",
       "      <td>0.0283784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_809.txt</td>\n",
       "      <td>0.0558275</td>\n",
       "      <td>0.069993</td>\n",
       "      <td>0.156681</td>\n",
       "      <td>0.0190342</td>\n",
       "      <td>0.358553</td>\n",
       "      <td>0.431873</td>\n",
       "      <td>0.394698</td>\n",
       "      <td>0.142071</td>\n",
       "      <td>0.178258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0370238</td>\n",
       "      <td>0.156779</td>\n",
       "      <td>0.0900571</td>\n",
       "      <td>0.347557</td>\n",
       "      <td>0.104849</td>\n",
       "      <td>0.0186037</td>\n",
       "      <td>0.0184544</td>\n",
       "      <td>0.190921</td>\n",
       "      <td>0.114629</td>\n",
       "      <td>0.024276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_1383.txt</td>\n",
       "      <td>0.382035</td>\n",
       "      <td>0.382427</td>\n",
       "      <td>0.0778835</td>\n",
       "      <td>0.00725576</td>\n",
       "      <td>0.0992691</td>\n",
       "      <td>0.0212028</td>\n",
       "      <td>0.266773</td>\n",
       "      <td>0.0454838</td>\n",
       "      <td>0.257237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0243531</td>\n",
       "      <td>0.049127</td>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.0933179</td>\n",
       "      <td>0.24236</td>\n",
       "      <td>0.00692002</td>\n",
       "      <td>0.00670784</td>\n",
       "      <td>0.251923</td>\n",
       "      <td>0.0898142</td>\n",
       "      <td>0.0203188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_983.txt</td>\n",
       "      <td>0.117034</td>\n",
       "      <td>0.14571</td>\n",
       "      <td>0.126163</td>\n",
       "      <td>0.0132169</td>\n",
       "      <td>0.243777</td>\n",
       "      <td>0.293902</td>\n",
       "      <td>0.359119</td>\n",
       "      <td>0.122018</td>\n",
       "      <td>0.274157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0302118</td>\n",
       "      <td>0.124041</td>\n",
       "      <td>0.133482</td>\n",
       "      <td>0.270059</td>\n",
       "      <td>0.14759</td>\n",
       "      <td>0.0122129</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.280071</td>\n",
       "      <td>0.080105</td>\n",
       "      <td>0.0349052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_1713.txt</td>\n",
       "      <td>0.406302</td>\n",
       "      <td>0.379168</td>\n",
       "      <td>0.0426529</td>\n",
       "      <td>0.00799054</td>\n",
       "      <td>0.0726156</td>\n",
       "      <td>0.0148352</td>\n",
       "      <td>0.322734</td>\n",
       "      <td>0.02845</td>\n",
       "      <td>0.243344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0182559</td>\n",
       "      <td>0.0313115</td>\n",
       "      <td>0.489093</td>\n",
       "      <td>0.0726283</td>\n",
       "      <td>0.233985</td>\n",
       "      <td>0.00772974</td>\n",
       "      <td>0.00741196</td>\n",
       "      <td>0.198349</td>\n",
       "      <td>0.054791</td>\n",
       "      <td>0.0535518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       File_Name          0         1          2           3          4  \\\n",
       "0  file_2300.txt  0.0590446  0.110904   0.123339  0.00779356   0.269485   \n",
       "1   file_809.txt  0.0558275  0.069993   0.156681   0.0190342   0.358553   \n",
       "2  file_1383.txt   0.382035  0.382427  0.0778835  0.00725576  0.0992691   \n",
       "3   file_983.txt   0.117034   0.14571   0.126163   0.0132169   0.243777   \n",
       "4  file_1713.txt   0.406302  0.379168  0.0426529  0.00799054  0.0726156   \n",
       "\n",
       "           5         6          7         8  ...         12         13  \\\n",
       "0   0.190301  0.408658  0.0905355  0.266962  ...  0.0278881  0.0536573   \n",
       "1   0.431873  0.394698   0.142071  0.178258  ...  0.0370238   0.156779   \n",
       "2  0.0212028  0.266773  0.0454838  0.257237  ...  0.0243531   0.049127   \n",
       "3   0.293902  0.359119   0.122018  0.274157  ...  0.0302118   0.124041   \n",
       "4  0.0148352  0.322734    0.02845  0.243344  ...  0.0182559  0.0313115   \n",
       "\n",
       "          14         15        16          17          18        19  \\\n",
       "0   0.318561   0.293053  0.163751  0.00729391  0.00786818  0.262812   \n",
       "1  0.0900571   0.347557  0.104849   0.0186037   0.0184544  0.190921   \n",
       "2     0.3976  0.0933179   0.24236  0.00692002  0.00670784  0.251923   \n",
       "3   0.133482   0.270059   0.14759   0.0122129    0.012864  0.280071   \n",
       "4   0.489093  0.0726283  0.233985  0.00772974  0.00741196  0.198349   \n",
       "\n",
       "          20         21  \n",
       "0  0.0469967  0.0283784  \n",
       "1   0.114629   0.024276  \n",
       "2  0.0898142  0.0203188  \n",
       "3   0.080105  0.0349052  \n",
       "4   0.054791  0.0535518  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_preds = pd.DataFrame(columns = train_data.Labels.unique().tolist())\n",
    "test_set_preds.insert(0, 'File_Name', test_data.File_Name)\n",
    "test_set_preds.iloc[:,1:] = final_pred\n",
    "#Reorder the columns to match the Sample_submission_file\n",
    "test_set_preds = test_set_preds[['File_Name',0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
    "#Write your submissions to an excel file\n",
    "test_set_preds.to_excel('ensemble_trick_.22.xlsx', index=False)\n",
    "test_set_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach 2 Global Tokenizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "text.Tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_tokenizer = text.Tokenizer()\n",
    "\n",
    "global_tokenizer.fit_on_texts(train_data.post_processed_script)\n",
    "\n",
    "\n",
    "\n",
    "#list(train_data['processed_script']) + list(test_data['processed_script'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab size \n",
    "vocab_size = len(global_tokenizer.word_counts) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for class_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting classes Int64Index([6, 19, 4, 0], dtype='int64')\n",
      "19    261\n",
      "4     243\n",
      "6     230\n",
      "0     203\n",
      "dtype: int64\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 128)               66560     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 67,076\n",
      "Trainable params: 67,076\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 655 samples, validate on 282 samples\n",
      "Epoch 1/20\n",
      " 64/655 [=>............................] - ETA: 7:02 - loss: 0.5624 - accuracy: 0.7500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-84251f898b74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     epochs=20)\n\u001b[0m\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\clive\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print('predicting classes {}'.format(class_model_1))\n",
    "\n",
    "x_1 = []\n",
    "y_1 = []\n",
    "\n",
    "\n",
    "\n",
    "for i in class_model_1:\n",
    "    \n",
    "    if i == 6:\n",
    "        x_1.extend(train_data[train_data.Labels == i]['post_processed_script'][0:230])\n",
    "        y_1.extend(train_data[train_data.Labels == i]['Labels'][0:230])\n",
    "    else:\n",
    "        x_1.extend(train_data[train_data.Labels == i]['post_processed_script'])\n",
    "        y_1.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "print(pd.Series(y_1).value_counts())        \n",
    "        \n",
    "\n",
    "\n",
    "sequences = global_tokenizer.texts_to_matrix(x_1,mode = 'tfidf')\n",
    "\n",
    "\n",
    "X_pad = pad_sequences(sequences,maxlen=5000,padding = 'post')\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "br = LabelBinarizer()\n",
    "\n",
    "br.fit(y_1)\n",
    "\n",
    "Y = br.transform(y_1)\n",
    "\n",
    "\n",
    "X_pad = X_pad.reshape(-1,5000,1)\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pad,\n",
    "    Y,\n",
    "    test_size=0.3,\n",
    "    shuffle = True,\n",
    "    random_state=3)    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "model = Sequential()\n",
    "# model.add(Embedding(input_dim= vocab_size,output_dim=8,input_length=5000))\n",
    "model.add(LSTM(128, recurrent_dropout=0.1,input_shape = (5000,1)))\n",
    "# model.add(MaxPool1D(12))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(16,activation = 'relu'))\n",
    "# model.add(Dense(128))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(32))\n",
    "model.add(Dense(len(class_model_1), activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=20)\n",
    "\n",
    "print(log_loss(y_train,model.predict(X_train)))\n",
    "print(log_loss(y_test,model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Model for class_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting classes Int64Index([5, 15, 1, 16, 11], dtype='int64')\n",
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_53 (Embedding)     (None, 15000, 8)          80000     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 1875, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_53 (Flatten)         (None, 15000)             0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 128)               1920128   \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 2,000,773\n",
      "Trainable params: 2,000,773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 483 samples, validate on 121 samples\n",
      "Epoch 1/10\n",
      "483/483 [==============================] - 5s 11ms/step - loss: 0.7047 - accuracy: 0.7255 - val_loss: 0.6048 - val_accuracy: 0.8000\n",
      "Epoch 2/10\n",
      "483/483 [==============================] - 4s 9ms/step - loss: 0.6007 - accuracy: 0.7901 - val_loss: 0.5137 - val_accuracy: 0.8000\n",
      "Epoch 3/10\n",
      "483/483 [==============================] - 5s 9ms/step - loss: 0.5376 - accuracy: 0.7839 - val_loss: 0.5167 - val_accuracy: 0.8000\n",
      "Epoch 4/10\n",
      "483/483 [==============================] - 5s 10ms/step - loss: 0.5106 - accuracy: 0.8000 - val_loss: 0.5049 - val_accuracy: 0.8000\n",
      "Epoch 5/10\n",
      "483/483 [==============================] - 5s 10ms/step - loss: 0.5039 - accuracy: 0.8000 - val_loss: 0.5019 - val_accuracy: 0.8000\n",
      "Epoch 6/10\n",
      "483/483 [==============================] - 4s 9ms/step - loss: 0.4949 - accuracy: 0.8000 - val_loss: 0.4940 - val_accuracy: 0.8000\n",
      "Epoch 7/10\n",
      "483/483 [==============================] - 4s 9ms/step - loss: 0.4884 - accuracy: 0.8000 - val_loss: 0.4886 - val_accuracy: 0.8000\n",
      "Epoch 8/10\n",
      "483/483 [==============================] - 5s 10ms/step - loss: 0.4810 - accuracy: 0.8000 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 9/10\n",
      "483/483 [==============================] - 5s 10ms/step - loss: 0.4731 - accuracy: 0.8000 - val_loss: 0.4790 - val_accuracy: 0.8000\n",
      "Epoch 10/10\n",
      "483/483 [==============================] - 4s 9ms/step - loss: 0.4644 - accuracy: 0.8000 - val_loss: 0.4744 - val_accuracy: 0.8000\n",
      "1.440381850391688\n",
      "1.5071242880230107\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('predicting classes {}'.format(class_model_2))\n",
    "\n",
    "x_2 = []\n",
    "y_2 = []\n",
    "for i in class_model_2:\n",
    "    \n",
    "    x_2.extend(train_data[train_data.Labels == i]['processed_script'])\n",
    "    y_2.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tokenizer2 = text.Tokenizer(num_words = 6000)\n",
    "# tokenizer2.fit_on_texts(x_2)\n",
    "sequences = global_tokenizer.texts_to_matrix(x_2)\n",
    "\n",
    "X_pad = pad_sequences(sequences,maxlen=15000)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "br2 = LabelBinarizer()\n",
    "\n",
    "br2.fit(y_2)\n",
    "\n",
    "Y = br2.transform(y_2)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pad,\n",
    "    Y,\n",
    "    stratify= Y,\n",
    "    test_size=0.2,\n",
    "    shuffle = True,\n",
    "    random_state=3)    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "model_2 = Sequential()\n",
    "model_2.add(Embedding(input_dim= 10000,output_dim=8,input_length=15000))\n",
    "# model.add(LSTM(128, recurrent_dropout=0.1))\n",
    "model_2.add(MaxPool1D(8))\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(128))\n",
    "# model.add(Dense(128))\n",
    "model_2.add(Dropout(0.3))\n",
    "# model.add(Dense(32))\n",
    "model_2.add(Dense(len(class_model_2), activation='softmax'))\n",
    "\n",
    "model_2.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "\n",
    "history = model_2.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=100,\n",
    "    epochs=10)\n",
    "\n",
    "\n",
    "print(log_loss(y_train,model_2.predict(X_train)))\n",
    "print(log_loss(y_test,model_2.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting classes Int64Index([8, 14, 7, 2, 20, 13, 21, 12, 9, 3, 17, 18, 10], dtype='int64')\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_71 (Embedding)     (None, 15000, 8)          80000     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 15000, 128)        70144     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 13)                1677      \n",
      "=================================================================\n",
      "Total params: 151,821\n",
      "Trainable params: 151,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 184 samples, validate on 79 samples\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('predicting classes {}'.format(class_model_3))\n",
    "\n",
    "x_3 = []\n",
    "y_3 = []\n",
    "for i in class_model_3:\n",
    "    \n",
    "    x_3.extend(train_data[train_data.Labels == i]['processed_script'])\n",
    "    y_3.extend(train_data[train_data.Labels == i]['Labels'])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tokenizer3 = text.Tokenizer(num_words = 6000)\n",
    "# tokenizer3.fit_on_texts(x_3)\n",
    "\n",
    "\n",
    "\n",
    "sequences = global_tokenizer.texts_to_matrix(x_3)\n",
    "\n",
    "X_pad = pad_sequences(sequences,maxlen=15000)\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "br3 = LabelBinarizer()\n",
    "\n",
    "br3.fit(y_3)\n",
    "\n",
    "Y = br3.transform(y_3)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pad,\n",
    "    Y,\n",
    "    stratify= Y,\n",
    "    test_size=0.3,\n",
    "    shuffle = True,\n",
    "    random_state=3)    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "model_3 = Sequential()\n",
    "model_3.add(Embedding(input_dim= 10000,output_dim=8,input_length=15000))\n",
    "model_3.add(LSTM(128, recurrent_dropout=0.3))\n",
    "# model_3.add(GlobalMaxPooling1D())\n",
    "# model_3.add(Flatten())\n",
    "# model_3.add(Dense(256))\n",
    "# model.add(Dense(128))\n",
    "# # model_3.add(Dropout(0.3))\n",
    "# model.add(Dense(32))\n",
    "model_3.add(Dense(len(class_model_3), activation='softmax'))\n",
    "\n",
    "model_3.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "\n",
    "history = model_3.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=64,\n",
    "    epochs=3)\n",
    "\n",
    "print(log_loss(y_train,model_3.predict(X_train)))\n",
    "print(log_loss(y_test,model_3.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking if models are any good on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 4)\n"
     ]
    }
   ],
   "source": [
    "pred1 = model.predict(X_test)\n",
    "pred2 = model_2.predict(X_test)\n",
    "pred3 = model_3.predict(X_test)\n",
    "\n",
    "size = X_test.shape[0]\n",
    "\n",
    "\n",
    "final_pred = np.zeros(shape = (size,22),dtype = 'float32')\n",
    "\n",
    "print(pred1.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stiching : (combining the outputs of all 3 models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4  6 19]\n",
      "[ 1  5 11 15 16]\n",
      "[ 2  3  7  8  9 10 12 13 14 17 18 20 21]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 273 is out of bounds for axis 0 with size 273",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-319-23e742238aea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#                 print(final_pred[row][i],pred_list[index[0][0]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mfinal_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 273 is out of bounds for axis 0 with size 273"
     ]
    }
   ],
   "source": [
    "\n",
    "# def get_preds(x):\n",
    "\n",
    "index_model_1 = br.classes_\n",
    "index_model_2 = br2.classes_\n",
    "index_model_3 = br3.classes_\n",
    "\n",
    "print(index_model_1)\n",
    "print(index_model_2)\n",
    "print(index_model_3)\n",
    "\n",
    "for row in range(size):\n",
    "    \n",
    "    for index_list,pred_list in zip([index_model_1,index_model_2,index_model_3],[pred1,pred2,pred3]):\n",
    "\n",
    "        for i in range(22):\n",
    "\n",
    "            if i in index_list:\n",
    "\n",
    "                index = np.where(index_list == i)\n",
    "#                 print(i,index[0][0])\n",
    "#                 print(final_pred[row][i],pred_list[index[0][0]])\n",
    "                \n",
    "                final_pred[row][i] = pred_list[row][index[0][0]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred777 = np.argmax(final_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test[pred777 == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1]\n",
      "[[0.1998239  0.12551732 0.2954262  0.3792326 ]]\n",
      "[[0.18729632 0.29565173 0.07183705 0.2905894  0.15462548]]\n",
      "[[0.00786015 0.03780861 0.01138598 0.4925472  0.02531686 0.02005535\n",
      "  0.02738457 0.03504599 0.23855843 0.00733564 0.04922697 0.03013035\n",
      "  0.01734385]]\n"
     ]
    }
   ],
   "source": [
    "sample = X_test[2]\n",
    "\n",
    "print(y_test[2])\n",
    "\n",
    "print(model.predict(sample.reshape(1,-1)))\n",
    "print(model_2.predict(sample.reshape(1,-1)))\n",
    "print(model_3.predict(sample.reshape(1,-1)))\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37874773, 0.18132798, 0.00723269, 0.03627384, 0.14956091,\n",
       "       0.28654882, 0.24669273, 0.01026894, 0.48427323, 0.02416245,\n",
       "       0.01876203, 0.07133985, 0.02613264, 0.03216102, 0.2603025 ,\n",
       "       0.30183902, 0.15894431, 0.00707526, 0.04958217, 0.22499858,\n",
       "       0.02749178, 0.01628139], dtype=float32)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating  log loss of entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4  6 19]\n",
      "[ 1  5 11 15 16]\n",
      "[ 2  3  7  8  9 10 12 13 14 17 18 20 21]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.6689509184087026"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = train_data['processed_script']\n",
    "Y = train_data['Labels']\n",
    "\n",
    "\n",
    "X_pad_full = pad_sequences(global_tokenizer.texts_to_sequences(X),15000)\n",
    "\n",
    "\n",
    "pred1 = model.predict(X_pad_full)\n",
    "pred2 = model_2.predict(X_pad_full)\n",
    "pred3 = model_3.predict(X_pad_full)\n",
    "\n",
    "size = X_pad_full.shape[0]\n",
    "\n",
    "\n",
    "final_pred = np.zeros(shape = (size,22),dtype = 'float32')\n",
    "\n",
    "\n",
    "index_model_1 = br.classes_\n",
    "index_model_2 = br2.classes_\n",
    "index_model_3 = br3.classes_\n",
    "\n",
    "print(index_model_1)\n",
    "print(index_model_2)\n",
    "print(index_model_3)\n",
    "\n",
    "for row in range(size):\n",
    "    \n",
    "    for index_list,pred_list in zip([index_model_1,index_model_2,index_model_3],[pred1,pred2,pred3]):\n",
    "\n",
    "        for i in range(22):\n",
    "\n",
    "            if i in index_list:\n",
    "\n",
    "                index = np.where(index_list == i)\n",
    "#                 print(i,index[0][0])\n",
    "#                 print(final_pred[row][i],pred_list[index[0][0]])\n",
    "                \n",
    "                final_pred[row][i] = pred_list[row][index[0][0]]\n",
    "\n",
    "\n",
    "log_loss(train_data['Labels'].values,final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing stiching for test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  4  6 19]\n",
      "[ 1  5 11 15 16]\n",
      "[ 2  3  7  8  9 10 12 13 14 17 18 20 21]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = test_data['processed_script']\n",
    "# Y = train_data['Labels']\n",
    "\n",
    "\n",
    "X_pad_full = pad_sequences(global_tokenizer.texts_to_sequences(X),15000)\n",
    "\n",
    "\n",
    "pred1 = model.predict(X_pad_full)\n",
    "pred2 = model_2.predict(X_pad_full)\n",
    "pred3 = model_3.predict(X_pad_full)\n",
    "\n",
    "size = X_pad_full.shape[0]\n",
    "\n",
    "\n",
    "final_pred = np.zeros(shape = (size,22),dtype = 'float32')\n",
    "\n",
    "\n",
    "index_model_1 = br.classes_\n",
    "index_model_2 = br2.classes_\n",
    "index_model_3 = br3.classes_\n",
    "\n",
    "print(index_model_1)\n",
    "print(index_model_2)\n",
    "print(index_model_3)\n",
    "\n",
    "for row in range(size):\n",
    "    \n",
    "    for index_list,pred_list in zip([index_model_1,index_model_2,index_model_3],[pred1,pred2,pred3]):\n",
    "\n",
    "        for i in range(22):\n",
    "\n",
    "            if i in index_list:\n",
    "\n",
    "                index = np.where(index_list == i)\n",
    "#                 print(i,index[0][0])\n",
    "#                 print(final_pred[row][i],pred_list[index[0][0]])\n",
    "                \n",
    "                final_pred[row][i] = pred_list[row][index[0][0]]\n",
    "\n",
    "\n",
    "# log_loss(train_data['Labels'].values,final_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>1</th>\n",
       "      <th>14</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>3</th>\n",
       "      <th>13</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>17</th>\n",
       "      <th>9</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_2300.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_809.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_1383.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_983.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_1713.txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       File_Name    8    4    6   16   15   19    1   14    0  ...    7    3  \\\n",
       "0  file_2300.txt  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "1   file_809.txt  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "2  file_1383.txt  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "3   file_983.txt  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "4  file_1713.txt  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  ...  NaN  NaN   \n",
       "\n",
       "    13   20   21   12   10   17    9   18  \n",
       "0  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_preds = pd.DataFrame(columns = train_data.Labels.unique().tolist())\n",
    "test_set_preds.insert(0, 'File_Name', test_data.File_Name)\n",
    "\n",
    "test_set_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>8</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>19</th>\n",
       "      <th>1</th>\n",
       "      <th>14</th>\n",
       "      <th>0</th>\n",
       "      <th>...</th>\n",
       "      <th>7</th>\n",
       "      <th>3</th>\n",
       "      <th>13</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>12</th>\n",
       "      <th>10</th>\n",
       "      <th>17</th>\n",
       "      <th>9</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file_2300.txt</td>\n",
       "      <td>0.179997</td>\n",
       "      <td>0.165534</td>\n",
       "      <td>0.104334</td>\n",
       "      <td>0.0139271</td>\n",
       "      <td>0.337738</td>\n",
       "      <td>0.102053</td>\n",
       "      <td>0.243308</td>\n",
       "      <td>0.212032</td>\n",
       "      <td>0.29192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0433663</td>\n",
       "      <td>0.10396</td>\n",
       "      <td>0.098329</td>\n",
       "      <td>0.378092</td>\n",
       "      <td>0.163825</td>\n",
       "      <td>0.0273076</td>\n",
       "      <td>0.0330796</td>\n",
       "      <td>0.238958</td>\n",
       "      <td>0.0207412</td>\n",
       "      <td>0.00813573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file_809.txt</td>\n",
       "      <td>0.224785</td>\n",
       "      <td>0.112996</td>\n",
       "      <td>0.0479852</td>\n",
       "      <td>0.0265388</td>\n",
       "      <td>0.296745</td>\n",
       "      <td>0.191697</td>\n",
       "      <td>0.167473</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>0.358768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0391936</td>\n",
       "      <td>0.0660432</td>\n",
       "      <td>0.299585</td>\n",
       "      <td>0.284031</td>\n",
       "      <td>0.135385</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>0.0348955</td>\n",
       "      <td>0.310997</td>\n",
       "      <td>0.0319124</td>\n",
       "      <td>0.0091878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file_1383.txt</td>\n",
       "      <td>0.186323</td>\n",
       "      <td>0.134444</td>\n",
       "      <td>0.0677134</td>\n",
       "      <td>0.0182299</td>\n",
       "      <td>0.353126</td>\n",
       "      <td>0.137415</td>\n",
       "      <td>0.192924</td>\n",
       "      <td>0.0852254</td>\n",
       "      <td>0.34689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0424515</td>\n",
       "      <td>0.152717</td>\n",
       "      <td>0.157133</td>\n",
       "      <td>0.365475</td>\n",
       "      <td>0.188888</td>\n",
       "      <td>0.0170025</td>\n",
       "      <td>0.0343105</td>\n",
       "      <td>0.267627</td>\n",
       "      <td>0.0235579</td>\n",
       "      <td>0.00649431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file_983.txt</td>\n",
       "      <td>0.190752</td>\n",
       "      <td>0.208206</td>\n",
       "      <td>0.178399</td>\n",
       "      <td>0.0159887</td>\n",
       "      <td>0.365073</td>\n",
       "      <td>0.111734</td>\n",
       "      <td>0.246223</td>\n",
       "      <td>0.251481</td>\n",
       "      <td>0.103202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0420709</td>\n",
       "      <td>0.089523</td>\n",
       "      <td>0.0378164</td>\n",
       "      <td>0.253548</td>\n",
       "      <td>0.203901</td>\n",
       "      <td>0.121253</td>\n",
       "      <td>0.042692</td>\n",
       "      <td>0.197952</td>\n",
       "      <td>0.0262414</td>\n",
       "      <td>0.0214281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file_1713.txt</td>\n",
       "      <td>0.349447</td>\n",
       "      <td>0.244317</td>\n",
       "      <td>0.0082905</td>\n",
       "      <td>0.0389071</td>\n",
       "      <td>0.124269</td>\n",
       "      <td>0.238044</td>\n",
       "      <td>0.182983</td>\n",
       "      <td>0.0111615</td>\n",
       "      <td>0.474891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0284956</td>\n",
       "      <td>0.0351755</td>\n",
       "      <td>0.245159</td>\n",
       "      <td>0.280089</td>\n",
       "      <td>0.0727647</td>\n",
       "      <td>0.00791956</td>\n",
       "      <td>0.0520025</td>\n",
       "      <td>0.343302</td>\n",
       "      <td>0.0317073</td>\n",
       "      <td>0.0182776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       File_Name         8         4          6         16        15  \\\n",
       "0  file_2300.txt  0.179997  0.165534   0.104334  0.0139271  0.337738   \n",
       "1   file_809.txt  0.224785  0.112996  0.0479852  0.0265388  0.296745   \n",
       "2  file_1383.txt  0.186323  0.134444  0.0677134  0.0182299  0.353126   \n",
       "3   file_983.txt  0.190752  0.208206   0.178399  0.0159887  0.365073   \n",
       "4  file_1713.txt  0.349447  0.244317  0.0082905  0.0389071  0.124269   \n",
       "\n",
       "         19         1         14         0  ...          7          3  \\\n",
       "0  0.102053  0.243308   0.212032   0.29192  ...  0.0433663    0.10396   \n",
       "1  0.191697  0.167473   0.022619  0.358768  ...  0.0391936  0.0660432   \n",
       "2  0.137415  0.192924  0.0852254   0.34689  ...  0.0424515   0.152717   \n",
       "3  0.111734  0.246223   0.251481  0.103202  ...  0.0420709   0.089523   \n",
       "4  0.238044  0.182983  0.0111615  0.474891  ...  0.0284956  0.0351755   \n",
       "\n",
       "          13        20         21          12         10        17          9  \\\n",
       "0   0.098329  0.378092   0.163825   0.0273076  0.0330796  0.238958  0.0207412   \n",
       "1   0.299585  0.284031   0.135385    0.011945  0.0348955  0.310997  0.0319124   \n",
       "2   0.157133  0.365475   0.188888   0.0170025  0.0343105  0.267627  0.0235579   \n",
       "3  0.0378164  0.253548   0.203901    0.121253   0.042692  0.197952  0.0262414   \n",
       "4   0.245159  0.280089  0.0727647  0.00791956  0.0520025  0.343302  0.0317073   \n",
       "\n",
       "           18  \n",
       "0  0.00813573  \n",
       "1   0.0091878  \n",
       "2  0.00649431  \n",
       "3   0.0214281  \n",
       "4   0.0182776  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set_preds.iloc[:,1:] = final_pred\n",
    "#Reorder the columns to match the Sample_submission_file\n",
    "test_set_preds = test_set_preds[['File_Name',0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21]]\n",
    "#Write your submissions to an excel file\n",
    "# test_set_preds.to_excel('ensemble_trick_1.xlsx', index=False)\n",
    "test_set_preds.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
