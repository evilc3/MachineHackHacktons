{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pk\n",
    "\n",
    "X = pk.load(open('x_f-9_smot','rb'))\n",
    "y =  pk.load(open('y_f-9_smot','rb'))\n",
    "\n",
    "test_data = pd.read_csv('Test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['grade_A_Component_1','max_luminosity','thickness',\n",
    "                   'xmin','xmax','ymin','ymax','pixel_area',\n",
    "                   'Component' ]\n",
    "test_data['Component'] = test_data['x_component_1'] + test_data['x_component_2'] + \\\n",
    "                         test_data['x_component_3'] + test_data['x_component_4'] + \\\n",
    "                         test_data['x_component_5']  \n",
    "\n",
    "test_data = test_data[feature_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n",
      "Accuracy: 0.8816901408450705\n",
      "F1 Score: 0.8771929824561403\n",
      "AUC Score: 0.9549609598171777\n",
      "Log loss 0.31122323222807896\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.9070422535211268\n",
      "F1 Score: 0.9014925373134328\n",
      "AUC Score: 0.9669904145242176\n",
      "Log loss 0.27782145921040957\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.9126760563380282\n",
      "F1 Score: 0.906906906906907\n",
      "AUC Score: 0.9743858312702343\n",
      "Log loss 0.20860728570321113\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8704225352112676\n",
      "F1 Score: 0.8654970760233918\n",
      "AUC Score: 0.942487145305656\n",
      "Log loss 0.36052872126995655\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.8898305084745762\n",
      "F1 Score: 0.8835820895522388\n",
      "AUC Score: 0.9391617989721983\n",
      "Log loss 0.3562678834985482\n",
      "\n",
      "\n",
      "Fold Score: 0.8869343184504223\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8901408450704226\n",
      "F1 Score: 0.8842729970326411\n",
      "AUC Score: 0.9517869612137371\n",
      "Log loss 0.32772160957333146\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8760563380281691\n",
      "F1 Score: 0.8720930232558138\n",
      "AUC Score: 0.9462959436297849\n",
      "Log loss 0.3437283756192269\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8901408450704226\n",
      "F1 Score: 0.8828828828828829\n",
      "AUC Score: 0.9528343807528725\n",
      "Log loss 0.30958852407115633\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8929577464788733\n",
      "F1 Score: 0.8848484848484849\n",
      "AUC Score: 0.9674665143147337\n",
      "Log loss 0.2516537964674665\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.9067796610169492\n",
      "F1 Score: 0.9032258064516129\n",
      "AUC Score: 0.9687509974783748\n",
      "Log loss 0.23348600294661256\n",
      "\n",
      "\n",
      "Fold Score: 0.885464638894287\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8760563380281691\n",
      "F1 Score: 0.8690476190476191\n",
      "AUC Score: 0.9528026407668381\n",
      "Log loss 0.31495884169407\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8845070422535212\n",
      "F1 Score: 0.8818443804034581\n",
      "AUC Score: 0.9553100996635562\n",
      "Log loss 0.29769510392177545\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.9042253521126761\n",
      "F1 Score: 0.8975903614457832\n",
      "AUC Score: 0.9694661334349012\n",
      "Log loss 0.24183850991072237\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8788732394366198\n",
      "F1 Score: 0.8708708708708708\n",
      "AUC Score: 0.957722338602171\n",
      "Log loss 0.2903417699351451\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.8700564971751412\n",
      "F1 Score: 0.8606060606060606\n",
      "AUC Score: 0.9605477353250982\n",
      "Log loss 0.29970898365820103\n",
      "\n",
      "\n",
      "Fold Score: 0.8759918584747582\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8732394366197183\n",
      "F1 Score: 0.8632218844984803\n",
      "AUC Score: 0.9468355233923696\n",
      "Log loss 0.3388129653655361\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.9126760563380282\n",
      "F1 Score: 0.9096209912536443\n",
      "AUC Score: 0.9643242556973275\n",
      "Log loss 0.2501953389795792\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.9042253521126761\n",
      "F1 Score: 0.8988095238095238\n",
      "AUC Score: 0.9613724369961277\n",
      "Log loss 0.2708947173593583\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8816901408450705\n",
      "F1 Score: 0.8764705882352941\n",
      "AUC Score: 0.9519456611439091\n",
      "Log loss 0.3259683467624234\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.8898305084745762\n",
      "F1 Score: 0.8835820895522388\n",
      "AUC Score: 0.9579303520699671\n",
      "Log loss 0.28375944418606386\n",
      "\n",
      "\n",
      "Fold Score: 0.8863410154698362\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8985915492957747\n",
      "F1 Score: 0.896551724137931\n",
      "AUC Score: 0.9589919380435473\n",
      "Log loss 0.2759142351962866\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8873239436619719\n",
      "F1 Score: 0.8802395209580839\n",
      "AUC Score: 0.9600710975687172\n",
      "Log loss 0.2779430510537659\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8704225352112676\n",
      "F1 Score: 0.8580246913580248\n",
      "AUC Score: 0.9359487081825685\n",
      "Log loss 0.3765887653513562\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.9098591549295775\n",
      "F1 Score: 0.9041916167664671\n",
      "AUC Score: 0.9626102964514696\n",
      "Log loss 0.260124918921431\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.867231638418079\n",
      "F1 Score: 0.8629737609329445\n",
      "AUC Score: 0.9597178333173737\n",
      "Log loss 0.312844261884092\n",
      "\n",
      "\n",
      "Fold Score: 0.8803962628306904\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8647887323943662\n",
      "F1 Score: 0.8562874251497005\n",
      "AUC Score: 0.9516600012695995\n",
      "Log loss 0.31835867796062356\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8873239436619719\n",
      "F1 Score: 0.880952380952381\n",
      "AUC Score: 0.9604202374150956\n",
      "Log loss 0.2658450404217079\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.9042253521126761\n",
      "F1 Score: 0.9017341040462428\n",
      "AUC Score: 0.9596267377642353\n",
      "Log loss 0.28364300452849434\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8788732394366198\n",
      "F1 Score: 0.8731563421828907\n",
      "AUC Score: 0.9570557988954485\n",
      "Log loss 0.30073863443152177\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.9011299435028248\n",
      "F1 Score: 0.8948948948948949\n",
      "AUC Score: 0.9567493376743592\n",
      "Log loss 0.28662108722816093\n",
      "\n",
      "\n",
      "Fold Score: 0.8814050294452219\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8901408450704226\n",
      "F1 Score: 0.8821752265861027\n",
      "AUC Score: 0.9608328572335428\n",
      "Log loss 0.2637057702561485\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8732394366197183\n",
      "F1 Score: 0.8688046647230321\n",
      "AUC Score: 0.9494699422332255\n",
      "Log loss 0.3473034459323011\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8929577464788733\n",
      "F1 Score: 0.888888888888889\n",
      "AUC Score: 0.9623563765631944\n",
      "Log loss 0.25958712497744774\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.895774647887324\n",
      "F1 Score: 0.8902077151335311\n",
      "AUC Score: 0.9592141179457881\n",
      "Log loss 0.27856167366134543\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.8954802259887006\n",
      "F1 Score: 0.8902077151335311\n",
      "AUC Score: 0.9609626863289604\n",
      "Log loss 0.2737008818124391\n",
      "\n",
      "\n",
      "Fold Score: 0.8840568420930172\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8873239436619719\n",
      "F1 Score: 0.8787878787878789\n",
      "AUC Score: 0.9627689963816417\n",
      "Log loss 0.3273906590896448\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.856338028169014\n",
      "F1 Score: 0.8468468468468469\n",
      "AUC Score: 0.9414397257665207\n",
      "Log loss 0.3475540785957041\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.9070422535211268\n",
      "F1 Score: 0.9032258064516129\n",
      "AUC Score: 0.9651177553481877\n",
      "Log loss 0.25134004313469965\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8901408450704226\n",
      "F1 Score: 0.8849557522123893\n",
      "AUC Score: 0.9614041769821621\n",
      "Log loss 0.26092369329895676\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.903954802259887\n",
      "F1 Score: 0.9011627906976745\n",
      "AUC Score: 0.9631331992722397\n",
      "Log loss 0.25126549046219065\n",
      "\n",
      "\n",
      "Fold Score: 0.8829958149992805\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.8901408450704226\n",
      "F1 Score: 0.8849557522123894\n",
      "AUC Score: 0.957182758839586\n",
      "Log loss 0.28842730036118214\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.9070422535211268\n",
      "F1 Score: 0.9026548672566372\n",
      "AUC Score: 0.9557227194820035\n",
      "Log loss 0.27722227008559086\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8647887323943662\n",
      "F1 Score: 0.8562874251497007\n",
      "AUC Score: 0.9501682219259824\n",
      "Log loss 0.33396617237356174\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8845070422535212\n",
      "F1 Score: 0.8761329305135952\n",
      "AUC Score: 0.9550244397892466\n",
      "Log loss 0.2968350960394838\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.9096045197740112\n",
      "F1 Score: 0.9053254437869822\n",
      "AUC Score: 0.9745283922244565\n",
      "Log loss 0.21537752803453747\n",
      "\n",
      "\n",
      "Fold Score: 0.885071283783861\n",
      "\n",
      "Fold: 1\n",
      "Accuracy: 0.9014084507042254\n",
      "F1 Score: 0.8955223880597015\n",
      "AUC Score: 0.955690979495969\n",
      "Log loss 0.3086404566904624\n",
      "\n",
      "\n",
      "Fold: 2\n",
      "Accuracy: 0.8619718309859155\n",
      "F1 Score: 0.8563049853372434\n",
      "AUC Score: 0.9375357074842887\n",
      "Log loss 0.3891913079827883\n",
      "\n",
      "\n",
      "Fold: 3\n",
      "Accuracy: 0.8816901408450705\n",
      "F1 Score: 0.8764705882352941\n",
      "AUC Score: 0.9610232971497492\n",
      "Log loss 0.2700211895594313\n",
      "\n",
      "\n",
      "Fold: 4\n",
      "Accuracy: 0.8873239436619719\n",
      "F1 Score: 0.8823529411764707\n",
      "AUC Score: 0.9581984383926871\n",
      "Log loss 0.2874512963748315\n",
      "\n",
      "\n",
      "Fold: 5\n",
      "Accuracy: 0.8926553672316384\n",
      "F1 Score: 0.882716049382716\n",
      "AUC Score: 0.9538446806473235\n",
      "Log loss 0.32476461050321936\n",
      "\n",
      "\n",
      "Fold Score: 0.8786733904382851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import log_loss,f1_score,accuracy_score,roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "from scipy.optimize import fmin \n",
    "\n",
    "err_score = []\n",
    "test_pred_lgb = []\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    err_lgb_ac = []\n",
    "    err_lgb_f1 = []\n",
    "    err_lgb_f1_c = []\n",
    "    err_lgb_auc = []\n",
    "    err_lgb_log_loss = []\n",
    "    \n",
    "    y_pred_tot_lgb = []\n",
    "    y_pred_tot_lgb_c = []\n",
    "    y_pred_tot_lgb_prob = []\n",
    "\n",
    "    cutoff_value = []\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    fold = StratifiedKFold(n_splits=5, shuffle=True, random_state=int(i*24))\n",
    "    i = 1\n",
    "    f = 0\n",
    "    for train_index, test_index in fold.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        m=LGBMClassifier(random_state=int(i*12), scale_pos_weight=2)\n",
    "\n",
    "        m.fit(X_train,y_train)\n",
    "\n",
    "        y_pred = m.predict(X_test)\n",
    "        y_pred_prob = m.predict_proba(X_test)[:,1]\n",
    "\n",
    "        test_pred = m.predict(test_data)\n",
    "        test_pred_proba = m.predict_proba(test_data)[:,1]\n",
    "\n",
    "\n",
    "        err_ac = accuracy_score(y_test, y_pred)\n",
    "        err_f1 = f1_score(y_test, y_pred)\n",
    "        err_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "        err_logloss = log_loss(y_test,y_pred_prob)\n",
    "        \n",
    "        \n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] = feature_columns\n",
    "        fold_importance_df[\"importance\"] = m.feature_importances_\n",
    "        fold_importance_df[\"fold\"] = i + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "\n",
    "        f += 1\n",
    "        print(\"Fold:\", f)\n",
    "        print(\"Accuracy:\", err_ac)\n",
    "        print('F1 Score:', err_f1)\n",
    "        print(\"AUC Score:\", err_auc)\n",
    "        print('Log loss',err_logloss)\n",
    "        print('\\n')\n",
    "\n",
    "        err_lgb_ac.append(err_ac)\n",
    "        err_lgb_f1.append(err_f1)\n",
    "        err_lgb_auc.append(err_auc)\n",
    "        err_lgb_log_loss.append(err_logloss)\n",
    "\n",
    "        y_pred_tot_lgb.append(test_pred)\n",
    "        y_pred_tot_lgb_prob.append(test_pred_proba)\n",
    "    \n",
    "    err_score.append(np.mean(err_lgb_f1))\n",
    "    test_pred_lgb.append(np.mean(y_pred_tot_lgb, 0).round().astype(int))\n",
    "    \n",
    "    print(\"Fold Score:\", np.mean(err_lgb_f1))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
